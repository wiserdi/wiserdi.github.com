<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Internet Download Manager 6.41 Build 2 Multilingual</title>
    <link href="/2022/08/10/idm6-41-b2/"/>
    <url>/2022/08/10/idm6-41-b2/</url>
    
    <content type="html"><![CDATA[<p>Download [*Internet Download Manager 6.41 Build 2 Multilingual Retail.rar*](stuff&#x2F;Internet Download Manager 6.41 Build 2 Multilingual Retail.rar)</p><h1 id="How-to-install"><a href="#How-to-install" class="headerlink" title="How to install"></a>How to install</h1><ul><li>Quit all anti-virus applications.</li><li>Double click *<strong>idman641build2f.exe*</strong> to install.</li><li>After the installation, don’t open <em>Internet Download Manager</em>. If it’s opened, close all processes of it in Task Manager (Ctrl + Shift + Esc).</li><li>Decompress <strong>*IDM_6.4x_Crack_v18.1.rar***, copy *<strong>IDM_6.4x_Crack_v18.1.exe*</strong> to the destination folder (<em>C:\Program Files (x86)\Internet Download Manager</em> by default)</strong><em>.*</em>*</li></ul><p>Password: 1234 <img src="/2022/08/10/idm6-41-b2/install.png" alt="img"></p><ul><li>Run *<strong>IDM_6.4x_Crack_v18.1.exe*</strong> and Apply the patch.</li><li>Done.</li></ul><p><img src="/2022/08/10/idm6-41-b2/verify.png" alt="img"></p><p><strong>File size: 11 MB</strong></p><p>Internet Download Manager is a shareware download manager owned by American company Tonec, Inc. which is based in New York City. It is only available for the Microsoft Windows operating system. Internet Download Manager is a tool that manages and schedule downloads. It can use full bandwidth.</p><p><a href="https://www.internetdownloadmanager.com/features2.html">See the features here</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>添加图片测试</title>
    <link href="/2022/08/10/add-some-pics/"/>
    <url>/2022/08/10/add-some-pics/</url>
    
    <content type="html"><![CDATA[<p><img src="/2022/08/10/add-some-pics/YunchengSaltLake.jpg" alt="YunchengSaltLake"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Kuroda Seiki</title>
    <link href="/2022/08/10/kuroda-seiki/"/>
    <url>/2022/08/10/kuroda-seiki/</url>
    
    <content type="html"><![CDATA[<p><img src="/img/image-20220810003244150.png" alt="image-20220810003244150"></p><p><a href="https://en.wikipedia.org/wiki/Kazoku">Viscount</a> <strong>Kuroda Seiki</strong> (黒田 清輝, August 9, 1866 – July 15, 1924) was a <a href="https://en.wikipedia.org/wiki/Japanese_people">Japanese</a> painter and teacher, noted for bringing Western art theory and practice to a wide Japanese audience.</p><p>He was among the leaders of the <em><a href="https://en.wikipedia.org/wiki/Y%C5%8Dga">yōga</a></em> (or Western-style) movement in late 19th and early 20th-century <a href="https://en.wikipedia.org/wiki/Japanese_painting">Japanese painting</a>, and has come to be remembered in Japan as “the father of Western-style painting.”</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Flume 学习笔记</title>
    <link href="/2022/08/09/flume/"/>
    <url>/2022/08/09/flume/</url>
    
    <content type="html"><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Flume 是一种分布式、可靠且可用的服务，用于高效收集、聚合和移动大量日志数据。它具有基于流数据流的简单灵活的架构。它具有可调整的可靠性机制以及许多故障转移和恢复机制，具有健壮性和容错性。它使用简单可扩展数据模型允许在线分析应用程序。</p><p><img src="/img/DevGuide_image00.png" alt="Agent component diagram"></p><p>实时读取服务器上的日志数据，将数据写入到HDFS</p><h3 id="Flume的优点"><a href="#Flume的优点" class="headerlink" title="Flume的优点"></a>Flume的优点</h3><ol><li><p>可以和任意存储进程集成</p></li><li><p>输入的数据速率大于写入目的的存储速率，Flume会进行缓冲，减小hdfs的压力</p></li><li><p>flume中在channel上支持事务，使用了两个事务模型(sender + reciever)，确保消息可靠发送</p><p>source-&gt;channel 和channel-&gt;sink ，只有事务中的所有的数据全部提交到channel，那么source才认为数据读取完成，同理，只有所有数据都别写出sink，才会从channel中移除</p></li></ol><h3 id="Flume的架构"><a href="#Flume的架构" class="headerlink" title="Flume的架构"></a>Flume的架构</h3><p><strong>Source</strong> 数据输入端的类型: </p><p>Avro Source<br>Thrift Source<br>Exec Source<br>JMS Source<br>JMS message converter<br>SSL and JMS Source<br>Spooling Directory Source<br>Event Deserializers<br>LINE<br>AVRO<br>BlobDeserializer<br>Taildir Source<br>Twitter 1% firehose Source (experimental)<br>Kafka Source<br>NetCat TCP Source<br>NetCat UDP Source<br>Sequence Generator Source<br>Syslog Sources<br>Syslog TCP Source<br>Multiport Syslog TCP Source<br>Syslog UDP Source<br>HTTP Source<br>JSONHandler<br>BlobHandler<br>Stress Source<br>Legacy Sources<br>Avro Legacy Source<br>Thrift Legacy Source<br>Custom Source<br>Scribe Source</p><p><strong>Sink</strong> 目的地的类型：</p><p>HDFS Sink<br>Hive Sink<br>Logger Sink<br>Avro Sink<br>Thrift Sink<br>IRC Sink<br>File Roll Sink<br>Null Sink<br>HBaseSinks<br>HBaseSink<br>HBase2Sink<br>AsyncHBaseSink<br>MorphlineSolrSink<br>ElasticSearchSink<br>Kite Dataset Sink<br>Kafka Sink<br>HTTP Sink<br>Custom Sink</p><p><strong>Channel</strong> 是source sink之间的缓冲，类型有:</p><p>Memory Channel : 基于内存的，你不关心日志是否丢失<br>JDBC Channel<br>Kafka Channel<br>File Channel ：保证数据不丢失，写入channel的数据会被持久化<br>Spillable Memory Channel<br>Pseudo Transaction Channel<br>Custom Channel</p><h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><ol><li><p>下载地址</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">https:</span>//flume.apache<span class="hljs-meta">.org</span>/download.html<br></code></pre></td></tr></table></figure></li><li><p>上传到&#x2F;opt&#x2F;software下</p></li><li><p>解压缩，记得切换到hadoop用户</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> -xzvf apache-flume-<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>-bin.tar.gz -C /opt/module/<br></code></pre></td></tr></table></figure></li><li><p>做软连接</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ln</span> -s apache-flume-<span class="hljs-number">1</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>-bin flume<br></code></pre></td></tr></table></figure></li><li><p>移除有冲突的jar包</p><p>将guava-11.0.2.jar包移除，或者改名也行</p><p>因为和hadoop下的冲突</p><p>&#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;guava-27.0-jre.jar</p><p>可以把上面的新的cp过来</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cp <span class="hljs-regexp">/opt/m</span>odule<span class="hljs-regexp">/hadoop/</span>share<span class="hljs-regexp">/hadoop/</span>common<span class="hljs-regexp">/lib/gu</span>ava-<span class="hljs-number">27.0</span>-jre.jar <span class="hljs-regexp">/opt/m</span>odule<span class="hljs-regexp">/flume/</span>lib/<br></code></pre></td></tr></table></figure></li></ol><h2 id="案例一-监控本地端口"><a href="#案例一-监控本地端口" class="headerlink" title="案例一: 监控本地端口"></a>案例一: 监控本地端口</h2><p>NetCat TCP</p><p>使用Flume监听一个端口，收集这个端口的数据，打印到控制台，或者输出到文件</p><ol><li><p>下载安装netcat</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">sudo yum <span class="hljs-keyword">install</span> -y nc<br></code></pre></td></tr></table></figure></li><li><p>配置flume的配置文件</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-built_in">mkdir</span> jobs<br><span class="hljs-keyword">vi</span> flume-nc.<span class="hljs-keyword">conf</span><br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-comment"># a1 是agent的名字，随便起，后面启动flume的时候要对应这个名字</span><br><span class="hljs-comment"># r1 是source的名字</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-comment"># k1是sink的名字</span><br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-comment"># c1是channel的名字</span><br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># r1的类型是netcat</span><br><span class="hljs-attr">a1.sources.r1.type</span> = netcat<br><span class="hljs-comment"># 绑定的ip地址是localhost</span><br><span class="hljs-attr">a1.sources.r1.bind</span> = localhost<br><span class="hljs-comment"># 绑定的端口是44444</span><br><span class="hljs-attr">a1.sources.r1.port</span> = <span class="hljs-number">44444</span><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-comment"># 配置 sink</span><br><span class="hljs-comment"># sink的类型是日志类型</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-comment"># 把 source和sink 跟channel 连接起来</span><br><span class="hljs-comment"># r1的channel是c1</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 <br><span class="hljs-comment"># k1的channel是c1</span><br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure></li><li><p>检查端口是否被占用</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> netstat -nlp | grep <span class="hljs-number">44444</span><br><br><span class="hljs-attribute">tcp6</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span> <span class="hljs-number">127.0.0.1:44444</span>         :::*                    LISTEN      <span class="hljs-number">22600</span>/java  <br></code></pre></td></tr></table></figure><p>上面就是44444端口被一个java进程占用，进程id是22600</p><p>杀掉进程</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">kill</span> <span class="hljs-number">22600</span><br></code></pre></td></tr></table></figure></li><li><p>启动flume</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ bin/flume-ng agent --conf conf --conf-file jobs/flume-nc.conf --name a1 -Dflume.root.<span class="hljs-attribute">logger</span>=INFO,console<br><br>--conf conf 配置文件在什么地方，跟的是个目录<br>--conf-file flume本次运行的配置文件(source sink channel的配置)<br>--name agent的名字<br>-Dflume.root.<span class="hljs-attribute">logger</span>=INFO,console 运行时参数flume.root.logger修改为INFO,console，让日志在控制台输出，输出的级别是INFO，日志级别<span class="hljs-built_in">DEBUG</span> <span class="hljs-built_in">INFO</span> WARN <span class="hljs-built_in">ERROR</span><br><br>简写<br>bin/flume-ng agent -c conf -n a1 -f jobs/flume-nc.conf<br></code></pre></td></tr></table></figure></li><li><p>启动nc发送数据</p><p>打开另外一个远程连接窗口执行</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nc</span> localhost <span class="hljs-number">44444</span><br></code></pre></td></tr></table></figure><p>输入内容</p><p>在flume运行的窗口就会收到信息</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-attr">[INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)]</span> Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">68</span> <span class="hljs-number">65</span> <span class="hljs-number">6</span>C <span class="hljs-number">6</span>C <span class="hljs-number">6</span>F                                  hello &#125;<br><br><span class="hljs-number">2022</span>-<span class="hljs-number">04</span>-<span class="hljs-number">21</span> <span class="hljs-number">22</span>:<span class="hljs-number">59</span>:<span class="hljs-number">31</span>,<span class="hljs-number">374</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: E4 BD <span class="hljs-number">95</span> E5 <span class="hljs-number">85</span> B5 E5 AE B6                      ......... &#125;<br><br></code></pre></td></tr></table></figure></li></ol><h2 id="案例二：实时监控单个文件，保存到hdfs中"><a href="#案例二：实时监控单个文件，保存到hdfs中" class="headerlink" title="案例二：实时监控单个文件，保存到hdfs中"></a>案例二：实时监控单个文件，保存到hdfs中</h2><ol><li><p>配置下hdfs</p><p>之前的服务器已经配好了&#x2F;etc&#x2F;profiled.d&#x2F;hadoop_env.sh</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># JAVA_HOME</span><br><span class="hljs-built_in">export</span> <span class="hljs-attribute">JAVA_HOME</span>=/opt/module/jdk1.8.0_202<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-variable">$PATH</span>:$JAVA_HOME/bin<br><br><span class="hljs-comment"># HADOOP_HOME</span><br><span class="hljs-built_in">export</span> <span class="hljs-attribute">HADOOP_HOME</span>=/opt/module/hadoop<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-variable">$PATH</span>:$HADOOP_HOME/bin<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-variable">$PATH</span>:$HADOOP_HOME/sbin<br><br></code></pre></td></tr></table></figure></li><li><p>创建flume配置文件</p><p>jobs&#x2F;flume-file-hdfs.conf</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1<br><span class="hljs-attr">a1.sinks</span> = k1<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source 一个可执行的命令</span><br><span class="hljs-attr">a1.sources.r1.type</span> = exec<br><span class="hljs-comment"># 命令是tail -F</span><br><span class="hljs-attr">a1.sources.r1.command</span> = tail -F /tmp/njust.log<br><br><span class="hljs-comment"># 配置sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hdfs<br><span class="hljs-comment"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.path</span> = hdfs://hadoop201:<span class="hljs-number">8020</span>/flume/events/%y-%m-%d/%H%M<br><span class="hljs-comment"># 上传文件的前缀</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.filePrefix</span> = events-<br><span class="hljs-comment"># 是否应该按时间滚动文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.round</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 10分钟生成一个文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="hljs-number">10</span><br><span class="hljs-comment"># 定义时间单位</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundUnit</span> = minute<br><span class="hljs-comment"># 使用本地时间戳</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure></li><li><p>运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">bin/flume-ng agent -c conf -n a1 -f <span class="hljs-built_in">jobs</span>/flu-file-hdfs.conf</span> <br></code></pre></td></tr></table></figure><p>往&#x2F;tmp&#x2F;njust.log里面加东西</p><p> 观察hdfs的目录</p></li></ol><h2 id="案例三-实时监控目录"><a href="#案例三-实时监控目录" class="headerlink" title="案例三: 实时监控目录"></a>案例三: 实时监控目录</h2><p>只监控目录下的新文件，.complete就不管了</p><ol><li><p>配置</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1<br><span class="hljs-attr">a1.sinks</span> = k1<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source spooldir 监控目录的source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = spooldir<br><span class="hljs-comment"># 配置监控目录</span><br><span class="hljs-attr">a1.sources.r1.spoolDir</span> = /tmp/hadoop<br><span class="hljs-comment"># 是否添加文件绝对路径当文件头</span><br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 文件上传好以后，会被改名，后缀是什么</span><br><span class="hljs-attr">a1.sources.r1.fileSuffix</span> = .COMPLETED<br><span class="hljs-comment"># includePattern 可以用正则表达式来配置哪些文件名的文件要上传</span><br><span class="hljs-comment"># ignorePattern 哪些忽略</span><br><br><br><br><span class="hljs-comment"># 配置sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hdfs<br><span class="hljs-comment"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.path</span> = hdfs://hadoop201:<span class="hljs-number">8020</span>/flume/events/%y-%m-%d/%H%M<br><span class="hljs-comment"># 上传文件的前缀</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.filePrefix</span> = events-<br><span class="hljs-comment"># 是否应该按时间滚动文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.round</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 10分钟生成一个文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="hljs-number">10</span><br><span class="hljs-comment"># 定义时间单位</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundUnit</span> = minute<br><span class="hljs-comment"># 使用本地时间戳</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 多久生成一个新文件</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.hdfs.rollInterval</span> = <span class="hljs-number">60</span><br><span class="hljs-comment"># 一次写100个Event到hdfs</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize</span> = <span class="hljs-number">100</span><br><br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure></li><li><p>运行</p></li></ol><h2 id="案例四-实时监控目录下多个文件追加"><a href="#案例四-实时监控目录下多个文件追加" class="headerlink" title="案例四 实时监控目录下多个文件追加"></a>案例四 实时监控目录下多个文件追加</h2><p>exec source 是一个文件</p><p>Taildir source 适用监听多个追加文件，而且支持断点续传</p><ol><li><p>配置flume-taildir-hdfs.conf</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1<br><span class="hljs-attr">a1.sinks</span> = k1<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source taildir 监控目录下的多个文件追加</span><br><span class="hljs-attr">a1.sources.r1.type</span> = TAILDIR<br><span class="hljs-attr">a1.sources.r1.positionFile</span> = /tmp/hadoop/flume/taildir_position.json<br><span class="hljs-comment"># 指示有几个文件组，中间用空格分开</span><br><span class="hljs-attr">a1.sources.r1.filegroups</span> = f1 f2<br><span class="hljs-comment"># 定义f1文件组的文件，可以是单个文件</span><br><span class="hljs-attr">a1.sources.r1.filegroups.f1</span> = /tmp/hadoop/test1/example.log<br><span class="hljs-attr">a1.sources.r1.headers.f1.headerKey1</span> = value1<br><span class="hljs-attr">a1.sources.r1.filegroups.f2</span> = /tmp/hadoop/test2/.*log.*<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey1</span> = value2<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="hljs-number">2</span><br><span class="hljs-comment"># 日志里面用文件的绝对路径做头</span><br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><span class="hljs-attr">a1.sources.ri.maxBatchCount</span> = <span class="hljs-number">1000</span><br><br><br><span class="hljs-comment"># 配置sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hdfs<br><span class="hljs-comment"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.path</span> = hdfs://hadoop201:<span class="hljs-number">8020</span>/flume/events/%y-%m-%d/%H%M<br><span class="hljs-comment"># 上传文件的前缀</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.filePrefix</span> = events-<br><span class="hljs-comment"># 是否应该按时间滚动文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.round</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 10分钟生成一个文件夹</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="hljs-number">10</span><br><span class="hljs-comment"># 定义时间单位</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.roundUnit</span> = minute<br><span class="hljs-comment"># 使用本地时间戳</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 多久生成一个新文件</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.hdfs.rollInterval</span> = <span class="hljs-number">60</span><br><span class="hljs-comment"># 一次写100个Event到hdfs</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize</span> = <span class="hljs-number">100</span><br><br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure></li></ol><h2 id="Flume-事务"><a href="#Flume-事务" class="headerlink" title="Flume 事务"></a>Flume 事务</h2><p>Flume agent中间有三个组件，source  channel  sink，里面流的东西是event ，event由head和body组成</p><p>事务分两个部分</p><h3 id="put事务"><a href="#put事务" class="headerlink" title="put事务"></a>put事务</h3><p>source -&gt; channel的部分 </p><p><img src="/img/FFFFFF-t_70_pic_center.png"></p><p>首先Source会采集一批数据，封装为event，缓存达到batch data的最大容量时（batch data的大小取决于配置参数batch size的值），Flume开启事务：</p><p>doPut（）:将这批event写入到临时缓冲区putList，putList是一个LinkedBlockingDeque<br>，大小取决于配置Channel的参数transaction capacity的大小。</p><p>doCommit（）:检查channel内存队列是否足够合并，内存队列的大小由Channel的capacity参数控制， Channel的容量内存队列足够的时候，提交event成功。</p><p>doRollback（）: channel内存队列空间不够时，回滚，这里会将整个putList中的数据都扔掉，然后给Source返回一个ChannelException异常，告诉Source数据没有采集上。Source会重新采集这批数据，然后开启新的事务。</p><h3 id="Take事务"><a href="#Take事务" class="headerlink" title="Take事务"></a>Take事务</h3><p>channel -&gt; sink </p><p><img src="/img/pic_center-16511116964952.png"></p><p>doTake（）：sink将数据剪切取到临时缓冲区takeList，takeList也是一个LinkedBlockingDeque，<br>大小取决于配置Channel的参数transaction capacity的大小，同时也拷贝一份放入写往HDFS的IO流中。</p><p>doCommit（）：如果event全部发送成功，就清除takeList。</p><p>doRollback（）：如果发送过程中出现异常，回滚，将takeList中的全部event归还给Channel。这个操作可能导致数据重复,如果已经写入一半的event到了HDFS，但是回滚时会向channel归还整个takeList中的event，后续再次开启事务向HDFS写入这批event时候，就出现了数据重复。</p><p>Flume的事务仅能保证两个传输阶段的数据不丢，但是如果channel选用的是memory channel，那么由于memory channel将数据存储在内存中，一旦channel发生异常，数据仍然可能丢失，但采用File channel时，数据传输到channel时会落盘，再结合事务，会保证整体上数据不会丢失，但是仍然可能会在take事务阶段发生数据重复。</p><h2 id="Flume-重要组件"><a href="#Flume-重要组件" class="headerlink" title="Flume 重要组件"></a>Flume 重要组件</h2><p><img src="/img/t_70_pic_center.png"></p><ol><li><p>Flume Channel Selectors ( 3 种 )</p><p>作用就是选出event该去哪个channel，默认就是replicating（复制）</p><p>Replicating Channel Selector</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1 c2 c3<br><span class="hljs-comment"># 定义channel的选择器是复制, 将source来的一个event  c1 c2 c3都复制发一份</span><br><span class="hljs-attr">a1.sources.r1.selector.type</span> = replicating<br><span class="hljs-comment"># 定义了3个channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 c2 c3<br><span class="hljs-comment"># c3如果数据出问题，不管，c1 c2没配置，则必须执行事务</span><br><span class="hljs-attr">a1.sources.r1.selector.optional</span> = c3<br></code></pre></td></tr></table></figure><p>Multiplexing Channel Selector</p><p>会将event根据条件发到不同的channel</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">a1<span class="hljs-selector-class">.sources</span> = r1<br>a1<span class="hljs-selector-class">.channels</span> = c1 c2 c3 c4<br>a1<span class="hljs-selector-class">.sources</span><span class="hljs-selector-class">.r1</span><span class="hljs-selector-class">.selector</span><span class="hljs-selector-class">.type</span> = multiplexing<br>a1<span class="hljs-selector-class">.sources</span><span class="hljs-selector-class">.r1</span><span class="hljs-selector-class">.selector</span><span class="hljs-selector-class">.header</span> = state<br>a1<span class="hljs-selector-class">.sources</span><span class="hljs-selector-class">.r1</span><span class="hljs-selector-class">.selector</span><span class="hljs-selector-class">.mapping</span><span class="hljs-selector-class">.CZ</span> = c1<br>a1<span class="hljs-selector-class">.sources</span><span class="hljs-selector-class">.r1</span><span class="hljs-selector-class">.selector</span><span class="hljs-selector-class">.mapping</span><span class="hljs-selector-class">.US</span> = c2 c3<br>a1<span class="hljs-selector-class">.sources</span><span class="hljs-selector-class">.r1</span><span class="hljs-selector-class">.selector</span><span class="hljs-selector-class">.default</span> = c4<br></code></pre></td></tr></table></figure></li></ol><p>​Custom Channel Selector  自定义的</p><p>​implementation of the ChannelSelector interface</p><ol start="2"><li><p>Flume Sink Processors</p><p>Default Sink Processor：对应单个sink</p><p>Failover Sink Processor: 维护一个有优先级的水池列表，确保 event一定会被处理（送达）,失败的会处理</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">a1.sinkgroups</span> = g1<br><span class="hljs-attr">a1.sinkgroups.g1.sinks</span> = k1 k2<br><span class="hljs-attr">a1.sinkgroups.g1.processor.type</span> = failover<br><span class="hljs-comment"># 必配 sink优先级，数字越大优先级越高</span><br><span class="hljs-attr">a1.sinkgroups.g1.processor.priority.k1</span> = <span class="hljs-number">5</span><br><span class="hljs-attr">a1.sinkgroups.g1.processor.priority.k2</span> = <span class="hljs-number">10</span><br><span class="hljs-attr">a1.sinkgroups.g1.processor.maxpenalty</span> = <span class="hljs-number">10000</span><br></code></pre></td></tr></table></figure><p>Load balancing Sink Processor：实现负载均衡sinks</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">a1<span class="hljs-selector-class">.sinkgroups</span> = g1<br>a1<span class="hljs-selector-class">.sinkgroups</span><span class="hljs-selector-class">.g1</span><span class="hljs-selector-class">.sinks</span> = k1 k2<br>a1<span class="hljs-selector-class">.sinkgroups</span><span class="hljs-selector-class">.g1</span><span class="hljs-selector-class">.processor</span><span class="hljs-selector-class">.type</span> = load_balance<br>a1<span class="hljs-selector-class">.sinkgroups</span><span class="hljs-selector-class">.g1</span><span class="hljs-selector-class">.processor</span><span class="hljs-selector-class">.backoff</span> = true<br>a1<span class="hljs-selector-class">.sinkgroups</span><span class="hljs-selector-class">.g1</span><span class="hljs-selector-class">.processor</span><span class="hljs-selector-class">.selector</span> = random<br></code></pre></td></tr></table></figure></li><li><p>Flume Interceptors</p><p>flume在执行中有能力去修改和丢弃event，Interceptors拦截器就是做这个的</p></li></ol><h2 id="Flume的拓扑结构"><a href="#Flume的拓扑结构" class="headerlink" title="Flume的拓扑结构"></a>Flume的拓扑结构</h2><ol><li><p>串联</p><p><img src="/img/UserGuide_image03.png" alt="Two agents communicating over Avro RPC"></p></li></ol><p>​      将多个flume按顺序连接起来，不建议串联太长，因为如果中间一个出问题，整个通道就都完了</p><ol start="2"><li>Consolidation 合并</li></ol><p><img src="/img/UserGuide_image02.png" alt="A fan-in flow using Avro RPC to consolidate events in one place"></p><p>​        大多数情况用这种，工作环境，服务器会非常多，将多个服务器的数据采集汇总，给每台服务器配一个flume，然后传送到一个统一的sink去汇总处理，日志分析</p><ol start="3"><li>Multiplexing the flow 多路复用</li></ol><p><img src="/img/UserGuide_image01.png" alt="A fan-out flow using a (multiplexing) channel selector"></p><p>​      支持将source分发到不同的channel，多个目的地</p><ol start="4"><li><p>Load-Balance负载均衡和Failover 故障切换</p><p><img src="/img/t_70_pic_center-16511166368648.png"></p></li></ol><p>将多个sink 组成一个组，sink组实现负载均衡和故障切换</p><h2 id="案例五-多路"><a href="#案例五-多路" class="headerlink" title="案例五 多路"></a>案例五 多路</h2><p>有一个FlumeA监控文件，会把变动发到FlumeB，FlumeB负责写入hdfs，FlumeA还会发送给FlumeC，FlumeC就直接输出到本地console或者文件</p><p><img src="/img/image-20220428115518751-165111812064810.png" alt="image-20220428115518751"></p><ol><li><p>配置文件 flume-file-flume.conf 用来将日志的内容发送到2个channel，两个sink</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1 c2<br><span class="hljs-attr">a1.sinks</span> = k1 k2<br><br><span class="hljs-comment"># 配置 source</span><br><span class="hljs-comment"># 配置 selector</span><br><span class="hljs-attr">a1.sources.r1.selector.type</span> = replicating<br><span class="hljs-attr">a1.sources.r1.type</span> = exec<br><span class="hljs-attr">a1.sources.r1.command</span> = tail -F /tmp/njust.log<br><span class="hljs-attr">a1.sources.r1.shell</span> = /bin/bash -c<br><br><span class="hljs-comment"># 配置sink k1</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = avro<br><span class="hljs-attr">a1.sinks.k1.hostname</span> = hadoop201<br><span class="hljs-attr">a1.sinks.k1.port</span> = <span class="hljs-number">4545</span><br><span class="hljs-comment"># 配置sink k2</span><br><span class="hljs-attr">a1.sinks.k2.type</span> = avro<br><span class="hljs-attr">a1.sinks.k2.hostname</span> = hadoop201<br><span class="hljs-attr">a1.sinks.k2.port</span> = <span class="hljs-number">4646</span><br><br><span class="hljs-comment"># 配置channel </span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># c2的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c2.type</span> = memory<br><span class="hljs-comment"># c2最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c2.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c2的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c2.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 c2<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br><span class="hljs-attr">a1.sinks.k2.channel</span> = c2<br></code></pre></td></tr></table></figure></li><li><p>配置文件 flume-flume-hdfs.conf 从flume到hdfs</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a2.sources</span> = r2<br><span class="hljs-attr">a2.channels</span> = c3<br><span class="hljs-attr">a2.sinks</span> = k3<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source 一个可执行的命令</span><br><span class="hljs-attr">a2.sources.r2.type</span> = avro<br><span class="hljs-attr">a2.sources.r2.bind</span> = hadoop201<br><span class="hljs-attr">a2.sources.r2.port</span> = <span class="hljs-number">4545</span><br><br><br><span class="hljs-comment"># 配置sink</span><br><span class="hljs-attr">a2.sinks.k3.type</span> = hdfs<br><span class="hljs-comment"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.path</span> = hdfs://hadoop201:<span class="hljs-number">8020</span>/flume/events2/%y-%m-%d/%H%M<br><span class="hljs-comment"># 上传文件的前缀</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.filePrefix</span> = events-<br><span class="hljs-comment"># 是否应该按时间滚动文件夹</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.round</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment"># 10分钟生成一个文件夹</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.roundValue</span> = <span class="hljs-number">10</span><br><span class="hljs-comment"># 定义时间单位</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.roundUnit</span> = minute<br><span class="hljs-comment"># 使用本地时间戳</span><br><span class="hljs-attr">a2.sinks.k3.hdfs.useLocalTimeStamp</span> = <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c3的类型是memory channel</span><br><span class="hljs-attr">a2.channels.c3.type</span> = memory<br><span class="hljs-comment"># c3最多能容纳1000个event</span><br><span class="hljs-attr">a2.channels.c3.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c3的事务提交100个提交一次</span><br><span class="hljs-attr">a2.channels.c3.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a2.sources.r2.channels</span> = c3<br><span class="hljs-attr">a2.sinks.k3.channel</span> = c3<br></code></pre></td></tr></table></figure></li><li><p>配置文件 flume-flume-local.conf 从flume到本地</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a3.sources</span> = r3<br><span class="hljs-attr">a3.channels</span> = c4<br><span class="hljs-attr">a3.sinks</span> = k4<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source 一个可执行的命令</span><br><span class="hljs-attr">a3.sources.r3.type</span> = avro<br><span class="hljs-attr">a3.sources.r3.bind</span> = hadoop201<br><span class="hljs-attr">a3.sources.r3.port</span> = <span class="hljs-number">4646</span><br><br><span class="hljs-comment"># 配置sink file roll sink</span><br><span class="hljs-attr">a3.sinks.k4.type</span> = file_roll<br><span class="hljs-comment"># 不会自动建目录，请一定要提前建好目录</span><br><span class="hljs-attr">a3.sinks.k4.sink.directory</span> = /tmp/hadoop/flume/logs<br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c4的类型是memory channel</span><br><span class="hljs-attr">a3.channels.c4.type</span> = memory<br><span class="hljs-comment"># c4最多能容纳1000个event</span><br><span class="hljs-attr">a3.channels.c4.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c4的事务提交100个提交一次</span><br><span class="hljs-attr">a3.channels.c4.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a3.sources.r3.channels</span> = c4<br><span class="hljs-attr">a3.sinks.k4.channel</span> = c4<br></code></pre></td></tr></table></figure></li></ol><h2 id="案例六-合并"><a href="#案例六-合并" class="headerlink" title="案例六 合并"></a>案例六 合并</h2><img src="/img/image-20220428145440550.png" alt="image-20220428145440550" style="zoom: 50%;"><ol><li><p>配置a1 flume-file-avro.conf</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1<br><span class="hljs-attr">a1.sinks</span> = k1<br><br><span class="hljs-comment"># 配置 source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = exec<br><span class="hljs-attr">a1.sources.r1.command</span> = tail -F /tmp/hadoop/test1/example.log<br><span class="hljs-attr">a1.sources.r1.shell</span> = /bin/bash -c<br><br><span class="hljs-comment"># 配置sink k1</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = avro<br><span class="hljs-attr">a1.sinks.k1.hostname</span> = hadoop203<br><span class="hljs-attr">a1.sinks.k1.port</span> = <span class="hljs-number">4545</span><br><br><span class="hljs-comment"># 配置channel </span><br><span class="hljs-comment"># c1的类型是memory channel</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure></li><li><p>配置a2 flume-nc-avro.conf</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a2.sources</span> = r2<br><span class="hljs-attr">a2.channels</span> = c2<br><span class="hljs-attr">a2.sinks</span> = k2<br><br><span class="hljs-comment"># 配置 source</span><br><span class="hljs-comment"># r2的类型是netcat</span><br><span class="hljs-attr">a2.sources.r2.type</span> = netcat<br><span class="hljs-comment"># 绑定的ip地址是localhost</span><br><span class="hljs-attr">a2.sources.r2.bind</span> = hadoop202<br><span class="hljs-comment"># 绑定的端口是44444</span><br><span class="hljs-attr">a2.sources.r2.port</span> = <span class="hljs-number">44444</span><br><br><span class="hljs-comment"># 配置sink k2</span><br><span class="hljs-attr">a2.sinks.k2.type</span> = avro<br><span class="hljs-attr">a2.sinks.k2.hostname</span> = hadoop203<br><span class="hljs-attr">a2.sinks.k2.port</span> = <span class="hljs-number">4545</span><br><br><span class="hljs-comment"># 配置channel </span><br><span class="hljs-comment"># c2的类型是memory channel</span><br><span class="hljs-attr">a2.channels.c2.type</span> = memory<br><span class="hljs-comment"># c1最多能容纳1000个event</span><br><span class="hljs-attr">a2.channels.c2.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c1的事务提交100个提交一次</span><br><span class="hljs-attr">a2.channels.c2.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a2.sources.r2.channels</span> = c2<br><span class="hljs-attr">a2.sinks.k2.channel</span> = c2<br></code></pre></td></tr></table></figure></li><li><p>配置a3 flume-avro-logger.conf</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 命名组件</span><br><span class="hljs-attr">a3.sources</span> = r3<br><span class="hljs-attr">a3.channels</span> = c3<br><span class="hljs-attr">a3.sinks</span> = k3<br><br><span class="hljs-comment"># 配置source</span><br><span class="hljs-comment"># source 一个可执行的命令</span><br><span class="hljs-attr">a3.sources.r3.type</span> = avro<br><span class="hljs-attr">a3.sources.r3.bind</span> = hadoop203<br><span class="hljs-attr">a3.sources.r3.port</span> = <span class="hljs-number">4545</span><br><br><span class="hljs-comment"># 配置sink logger</span><br><span class="hljs-attr">a3.sinks.k3.type</span> = logger<br><br><span class="hljs-comment"># 配置channel</span><br><span class="hljs-comment"># c3的类型是memory channel</span><br><span class="hljs-attr">a3.channels.c3.type</span> = memory<br><span class="hljs-comment"># c3最多能容纳1000个event</span><br><span class="hljs-attr">a3.channels.c3.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment"># c3的事务提交100个提交一次</span><br><span class="hljs-attr">a3.channels.c3.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># 连接起来</span><br><span class="hljs-attr">a3.sources.r3.channels</span> = c3<br><span class="hljs-attr">a3.sinks.k3.channel</span> = c3<br></code></pre></td></tr></table></figure></li></ol><h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p>有时不能满足实际需求，需要自定义Source和Sink</p><h3 id="案例一：自定义Source"><a href="#案例一：自定义Source" class="headerlink" title="案例一：自定义Source"></a>案例一：自定义Source</h3><p>输出自定义的内容，然后在控制台用logger输出</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> cn.edu.njust.flume;<br><br><span class="hljs-keyword">import</span> com.google.common.collect.Maps;<br><span class="hljs-keyword">import</span> java.nio.charset.Charset;<br><span class="hljs-keyword">import</span> java.util.Map;<br><span class="hljs-keyword">import</span> org.apache.flume.Context;<br><span class="hljs-keyword">import</span> org.apache.flume.Event;<br><span class="hljs-keyword">import</span> org.apache.flume.EventDeliveryException;<br><span class="hljs-keyword">import</span> org.apache.flume.PollableSource;<br><span class="hljs-keyword">import</span> org.apache.flume.conf.Configurable;<br><span class="hljs-keyword">import</span> org.apache.flume.event.EventBuilder;<br><span class="hljs-keyword">import</span> org.apache.flume.source.AbstractSource;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> notre</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@date</span> 2022/5/4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MySource</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractSource</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Configurable</span>, PollableSource &#123;<br><br>  <span class="hljs-comment">// 定义的属性为将来在job文件中配置的属性</span><br>  <span class="hljs-keyword">private</span> String content;<br>  <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> delay;<br><br>  <span class="hljs-comment">// 这个方法的作用就是在配置的配置文件中读属性</span><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">configure</span><span class="hljs-params">(Context context)</span> &#123;<br>    content = context.getString(<span class="hljs-string">&quot;content&quot;</span>, <span class="hljs-string">&quot;今天天气真好&quot;</span>);<br>    delay = context.getLong(<span class="hljs-string">&quot;delay&quot;</span>,<span class="hljs-number">2000L</span>);<br>  &#125;<br><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> Status <span class="hljs-title function_">process</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> EventDeliveryException &#123;<br>    <span class="hljs-keyword">try</span>&#123;<br>      <span class="hljs-comment">// 创建一个空的头</span><br>      Map&lt;String,String&gt; headMap = Maps.newHashMap();<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br>        <span class="hljs-comment">// 创建一个用来传递数据的Event</span><br>        <span class="hljs-type">Event</span> <span class="hljs-variable">event</span> <span class="hljs-operator">=</span> EventBuilder.withBody(content+i, Charset.forName(<span class="hljs-string">&quot;UTF-8&quot;</span>),headMap);<br>        <span class="hljs-comment">// 配置文件中配置了哪个channel连接到这个source，他就去拿哪个channel</span><br>        getChannelProcessor().processEvent(event);<br>        <span class="hljs-comment">// 休眠下（可以取消）</span><br>        Thread.sleep(delay);<br>      &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e) &#123;<br>      <span class="hljs-keyword">return</span> Status.BACKOFF;<br>    &#125;<br>    <span class="hljs-keyword">return</span> Status.READY;<br>  &#125;<br><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> <span class="hljs-type">long</span> <span class="hljs-title function_">getBackOffSleepIncrement</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>  &#125;<br><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> <span class="hljs-type">long</span> <span class="hljs-title function_">getMaxBackOffSleepInterval</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>  &#125;<br><br><br>&#125;<br><br></code></pre></td></tr></table></figure><p>idea如何打包</p><ol><li>先build module</li><li>在 project structure中添加一个artifact，配置为jar add–&gt;from modules with dependency</li><li>在右侧output layer中删除所有的dependency,保留Compile output的那个jar包</li></ol><p>在项目的out目录下找到打好的jar包</p><p>上传到flume下的lib目录下</p><p>修改jar包的权限<code>sodu chown hadoop:hadoop FlumeDemo.jar </code></p><p>配置jobs文件</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = cn.edu.njust.flume.MySource<br><span class="hljs-attr">a1.sources.r1.content</span> = hello<br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 <br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/flume-ng agent -c conf -n a1 -f <span class="hljs-built_in">jobs</span>/flume-mysource.conf -Dflume.root.logger=INFO,console<br></code></pre></td></tr></table></figure><h3 id="案例二：自定义Sink"><a href="#案例二：自定义Sink" class="headerlink" title="案例二：自定义Sink"></a>案例二：自定义Sink</h3><p>Sink一定要启动事务，从channel中拿取events，然后写入文件或者hdfs…</p><p>自定义一个Sink，监听netcat内容，加上前后缀，输出到Logger</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> cn.edu.njust.flume;<br><br><span class="hljs-keyword">import</span> org.apache.flume.Channel;<br><span class="hljs-keyword">import</span> org.apache.flume.Context;<br><span class="hljs-keyword">import</span> org.apache.flume.Event;<br><span class="hljs-keyword">import</span> org.apache.flume.EventDeliveryException;<br><span class="hljs-keyword">import</span> org.apache.flume.Transaction;<br><span class="hljs-keyword">import</span> org.apache.flume.conf.Configurable;<br><span class="hljs-keyword">import</span> org.apache.flume.sink.AbstractSink;<br><span class="hljs-keyword">import</span> org.slf4j.Logger;<br><span class="hljs-keyword">import</span> org.slf4j.LoggerFactory;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> notre</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@date</span> 2022/5/4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MySink</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractSink</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Configurable</span> &#123;<br><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">LOGGER</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(MySink.class);<br><br>  <span class="hljs-keyword">private</span> String prefix;<br>  <span class="hljs-keyword">private</span> String suffix;<br><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">configure</span><span class="hljs-params">(Context context)</span> &#123;<br>    prefix = context.getString(<span class="hljs-string">&quot;prefix&quot;</span>,<span class="hljs-string">&quot;begin-&quot;</span>);<br>    suffix = context.getString(<span class="hljs-string">&quot;suffix&quot;</span>, <span class="hljs-string">&quot;-end&quot;</span>);<br>  &#125;<br><br><br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> Status <span class="hljs-title function_">process</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> EventDeliveryException &#123;<br><br>    <span class="hljs-type">Channel</span> <span class="hljs-variable">ch</span> <span class="hljs-operator">=</span> getChannel();<br>    Event event;<br>    <span class="hljs-type">Transaction</span> <span class="hljs-variable">tx</span> <span class="hljs-operator">=</span> ch.getTransaction();<br>    tx.begin();<br>    <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>) &#123;<br>      event = ch.take();<br>      <span class="hljs-keyword">if</span>(event!=<span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-keyword">break</span>;<br>      &#125;<br>    &#125;<br>    <span class="hljs-keyword">try</span> &#123;<br>      LOGGER.info(prefix+ <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(event.getBody())+suffix);<br>      tx.commit();<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e) &#123;<br>      <span class="hljs-keyword">return</span> Status.BACKOFF;<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>      tx.close();<br>    &#125;<br>    <span class="hljs-keyword">return</span> Status.READY;<br>  &#125;<br><br><br>&#125;<br><br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = netcat<br><span class="hljs-attr">a1.sources.r1.bind</span> = localhost<br><span class="hljs-attr">a1.sources.r1.port</span> = <span class="hljs-number">44444</span><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = cn.edu.njust.flume.MySink<br><span class="hljs-attr">a1.sinks.k1.prefix</span> = njust-<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 <br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/flume-ng agent -n a1 -c conf -f <span class="hljs-built_in">jobs</span>/flume-mysink.conf -Dflume.root.logger=INFO,console<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2022《虚拟化与云计算应用》期末复习</title>
    <link href="/2022/08/09/virtualization-and-cloud-computing-final-exam-preparation/"/>
    <url>/2022/08/09/virtualization-and-cloud-computing-final-exam-preparation/</url>
    
    <content type="html"><![CDATA[<h2 id><a href="#" class="headerlink" title></a></h2><h3 id="云计算的概念-KBX-N4S-fmi"><a href="#云计算的概念-KBX-N4S-fmi" class="headerlink" title="云计算的概念(KBX, N4S, fmi)"></a>云计算的概念(KBX, N4S, fmi)</h3><p><a href="https://azure.microsoft.com/en-us/overview/what-is-cloud-computing/#cloud-deployment-types">https://azure.microsoft.com/en-us/overview/what-is-cloud-computing/#cloud-deployment-types</a></p><p>云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络、服务器、存储、应用软件、服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">Simply put, <span class="hljs-keyword">cloud </span>computing is the delivery of computing services—including servers, storage, databases, networking, software, analytics, <span class="hljs-keyword">and </span>intelligence—over the Internet (“the <span class="hljs-keyword">cloud”) </span>to offer faster innovation, flexible resources, <span class="hljs-keyword">and </span>economies of <span class="hljs-keyword">scale. </span>You typically pay only for <span class="hljs-keyword">cloud </span>services you use, helping you lower your operating costs, run your infrastructure more efficiently, <span class="hljs-keyword">and </span><span class="hljs-keyword">scale </span>as your <span class="hljs-keyword">business </span>needs change.<br></code></pre></td></tr></table></figure><p>复习参考：</p><p><a href="https://yangguoping.blog.csdn.net/article/details/109583017">https://yangguoping.blog.csdn.net/article/details/109583017</a></p><p><a href="https://blog.51cto.com/u_14540820/5191589">https://blog.51cto.com/u_14540820/5191589</a></p><p><a href="https://zhuanlan.zhihu.com/p/149636372">https://zhuanlan.zhihu.com/p/149636372</a></p><h3 id="云计算的优点-dd-v-te-extension-mc"><a href="#云计算的优点-dd-v-te-extension-mc" class="headerlink" title="云计算的优点(dd, v, te(extension), mc)"></a><strong>云计算的优点</strong>(dd, v, te(extension), mc)</h3><p>更快速的交付和部署 Faster delivery and deployment</p><p>更高效的虚拟化 More efficient virtualization</p><p>更轻松的迁移和扩展 Easier transfer and extension</p><p>更简单的管理 Simpler management</p><p>更低的成本 Lower cost</p><h3 id="云计算的分类"><a href="#云计算的分类" class="headerlink" title="云计算的分类"></a><strong>云计算的分类</strong></h3><p><strong>按运营模式分：</strong></p><ol><li>公有云 Public cloud</li><li>私有云 Private cloud</li><li>混合云 Hybrid cloud</li><li>社区云 Community cloud</li><li>行业云 Industry cloud</li></ol><p><strong>按提供的服务(Service)分：</strong></p><ol><li>IaaS基础设施及服务 Infrastructure as a service (IaaS)</li><li>PaaS平台及服务 Platform as a service (PaaS)</li><li>SaaS软件及服务 Software as a service (SaaS)</li><li>CaaS容器及服务 Containers as a service (CaaS)</li></ol><p>给你一个描述，或者给你一个产品，你要能分辨出是哪种服务</p><p>亚马逊的AWS属于IaaS基础设施及服务，Windows Azure属于PaaS平台及服务。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">IAAS</span><span class="hljs-params">(infrastructure 基础设施)</span></span>:硬件、裸机、裸金属、亚马逊的AWS<br><span class="hljs-function"><span class="hljs-title">SAAS</span><span class="hljs-params">(software 软件)</span></span>：Word等各种软件类<br><span class="hljs-function"><span class="hljs-title">PAAS</span><span class="hljs-params">(platform 平台)</span></span>:亚马逊的平台、Microsoft Azure<br><span class="hljs-function"><span class="hljs-title">CAAS</span><span class="hljs-params">(container 容器)</span></span>: Docker<br><br></code></pre></td></tr></table></figure><h3 id="云计算机制"><a href="#云计算机制" class="headerlink" title="云计算机制"></a><strong>云计算机制</strong></h3><p>云计算技术将<u>计算</u>资源、<u>存储</u>资源以及其他各类资源通过<u>网络以服务的形式</u>提供给资源<u>用户</u>。</p><p><strong>云存储机制</strong>：数据的安全性、完整性和保密性 (Confidentiality, security, integrity)</p><p><strong>云存储按存储等级</strong>：文件、块、数据集和对象存储 (Files, blocks, datasets, objects)</p><p>SAN 网络存储 (Storage Area Network)</p><h3 id="云基础设施"><a href="#云基础设施" class="headerlink" title="云基础设施"></a><strong>云基础设施</strong></h3><p>逻辑网络边界(logical separation)：将一组相关的基于云的IT资源与云中的其他主体（如非授权用户）<u>隔离</u>开来，其主要功能是网络分段和隔离，以保证区域内的IT设施的相对<u>独立性</u>。</p><p>虚拟服务器</p><p>云存储设备</p><p>云使用监控</p><p>资源复制</p><h3 id="虚拟化-virtualization-的定义"><a href="#虚拟化-virtualization-的定义" class="headerlink" title="虚拟化(virtualization)的定义"></a><strong>虚拟化(virtualization)的定义</strong></h3><p>虚拟化</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">是表示计算机资源的抽象方法。通过虚拟化可以用与访问抽象前资源一致的方法访问抽象后的资源。这种资源的抽象方法并不受实现、地理位置或底层资源的物理配置的限制。 <br></code></pre></td></tr></table></figure><p>虚拟化</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">是为某些事物创造的虚拟（相对于真实）版本，如操作系统、计算机系统、存储设备和网络资源等。虚拟化的对象是各种各样的资源,经过虚拟化后的逻辑资源对用户隐藏了不必要的细节，用户可以在虚拟环境中实现其在真实环境中的部分或者全部功能。<br></code></pre></td></tr></table></figure><h3 id="虚拟化优点"><a href="#虚拟化优点" class="headerlink" title="虚拟化优点"></a><strong>虚拟化优点</strong></h3><p>虚拟机</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">可支持实现物理资源和资源池的动态共享<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">提高资源利用率，特别是针对那些平均需求远低于需要为其提供专用资源的不同负载。<br></code></pre></td></tr></table></figure><p>虚拟化技术</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">将计算机的各种实体资源（<span class="hljs-meta">CPU</span>、内存、磁盘空间、网络适配器等），予以抽象、转换后呈现出来并可分割、组合为一个或多个电脑配置环境。<br></code></pre></td></tr></table></figure><h3 id="虚拟化技术学习了哪几种？"><a href="#虚拟化技术学习了哪几种？" class="headerlink" title="虚拟化技术学习了哪几种？"></a><strong>虚拟化技术学习了哪几种？</strong></h3><ol><li>VMware vSphere</li><li>KVM</li><li>OpenStack</li><li>Docker</li></ol><h3 id="服务器虚拟化"><a href="#服务器虚拟化" class="headerlink" title="服务器虚拟化"></a><strong>服务器虚拟化</strong></h3><p>支撑技术：(CPU, RAM, ROM, DEV&#x2F;IO, Network, Desktop虚拟化)</p><p>CPU 虚拟化、内存虚拟化、存储虚拟化、设备与IO 虚拟化、网络虚拟化、桌面虚拟化</p><h3 id="虚拟化功能-snapshot-clone-deployment-backup-cluster-hot-add-NUMA"><a href="#虚拟化功能-snapshot-clone-deployment-backup-cluster-hot-add-NUMA" class="headerlink" title="虚拟化功能(snapshot, clone, deployment, backup, cluster, hot-add, NUMA)"></a><strong>虚拟化功能</strong>(snapshot, clone, deployment, backup, cluster, hot-add, NUMA)</h3><p>虚拟机快照、虚拟机克隆、虚拟机按模板部署、虚拟机备份、虚拟化集群、虚拟机资源热添加、NUMA(Non-uniform memory access)</p><h3 id="网络常识"><a href="#网络常识" class="headerlink" title="网络常识"></a><strong>网络常识</strong></h3><p>计算机网络按<u>地理范围</u>可分为：</p><ol><li>局域网LAN(<strong>local area network</strong>)</li><li>城域网MAN(<strong>metropolitan area network</strong>)</li><li>广域网WAN(<strong>wide area network</strong>)</li></ol><p>互联网的拓扑结构：<strong>网状型</strong></p><h3 id="存储常识"><a href="#存储常识" class="headerlink" title="存储常识"></a><strong>存储常识</strong></h3><p><strong>独立硬盘冗余阵列</strong>（<strong>RAID</strong>, <strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>ndependent <strong>D</strong>isks），旧称<strong>廉价磁盘冗余阵列</strong>（<strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>nexpensive <strong>D</strong>isks），简称<strong>磁盘阵列</strong></p><p><strong>raid技术(0,1,5,6)：</strong>raid0 raid1 raid5 raid6</p><p>没有冗余：<strong>raid0</strong></p><p>冗余最高：<strong>raid1</strong></p><h3 id="vSphere"><a href="#vSphere" class="headerlink" title="vSphere"></a><strong>vSphere</strong></h3><p><a href="https://docs.vmware.com/en/VMware-vSphere/index.html">https://docs.vmware.com/en/VMware-vSphere/index.html</a></p><p><strong>vSphere由ESXi和vCenter Server组成</strong></p><p>ESXi: VMware <em>ESXi</em> (formerly ESX) is an enterprise-class, type-1 hypervisor developed by VMware for deploying and serving virtual computers. </p><p><img src="https://docs.vmware.com/en/VMware-vSphere/images/GUID-5EB66614-1EE8-4F39-8C8B-1E97EEE76791-high.png" alt="img"></p><p><strong>例</strong>：vCenter管理多台服务器<strong>（对）</strong></p><h3 id="iSCSI-x2F-ˈaɪskvzi-x2F-Internet-Small-Computer-Systems-Interface"><a href="#iSCSI-x2F-ˈaɪskvzi-x2F-Internet-Small-Computer-Systems-Interface" class="headerlink" title="iSCSI &#x2F;ˈaɪskʌzi&#x2F; (Internet Small Computer Systems Interface)"></a>iSCSI <a href="https://en.wikipedia.org/wiki/Help:IPA/English">&#x2F;ˈaɪskʌzi&#x2F;</a> (<em>Internet Small Computer Systems Interface</em>)</h3><p>vCenter Server提供了很多适应现代数据中心的高级特性：</p><ol><li>vMotion</li><li>vSphere HA</li><li>vSphere DRS</li></ol><p>例：(用SCSI协议不是http协议，而是TCP&#x2F;IP)</p><h3 id="vMotion实时迁移要求"><a href="#vMotion实时迁移要求" class="headerlink" title="vMotion实时迁移要求"></a><strong>vMotion实时迁移要求</strong></h3><p>（访问存储、千兆网卡、VMKernel、标准虚拟交换机、处理器、端口组）</p><p>①源和目标ESXi主机必须都能够访问保存虚拟机文件的共享存储（FC、FCoE或iSCSI）。</p><p>②源和目标ESXi主机必须具备千兆以太网卡或更快的网卡。</p><p>③源和目标ESXi主机上必须有支持vMotion的VMkernel端口。</p><p>④源和目标ESXi主机必须有相同的标准虚拟交换机。</p><p>⑤待迁移虚拟机连接到的所有虚拟机端口组在源和目标ESXi主机上都必须存在。</p><p>⑥源和目标ESXi主机的处理器必须兼容。</p><h3 id="vSphere的安装"><a href="#vSphere的安装" class="headerlink" title="vSphere的安装"></a><strong>vSphere的安装</strong></h3><p><strong>ESXi iSCSI的配置</strong></p><ol><li><p>在VMware Workstation的虚拟网络编辑器中，添加vmnet2虚拟网络，类型为仅主机模式。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dns">将vmnet1、vmnet2、vmnet8的网段分别设置为<span class="hljs-number">192.168.100.0</span>/<span class="hljs-number">24、192.168.200</span>.<span class="hljs-number">0/24、192.168</span>.<span class="hljs-number">80</span>.<span class="hljs-number">0</span>/<span class="hljs-number">24</span>。<br></code></pre></td></tr></table></figure></li><li><p>创建VMware ESXi虚拟机，内存为4GB，</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">为虚拟机配置3个网卡，网络类型分别为仅主机模式、NAT模式、vmnet2模式。<br></code></pre></td></tr></table></figure></li><li><p>安装VMware ESXi 5.5，</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm">将管理网络的<span class="hljs-built_in">IP</span>地址配置为<span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">100</span>.<span class="hljs-number">100</span>（仅主机模式）<br></code></pre></td></tr></table></figure></li><li><p>使用vSphere Client连接到ESXi，</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode">添加虚拟机端口组ForVM，创建标准交换机，绑定vm<span class="hljs-symbol">nic1</span>网卡。<br></code></pre></td></tr></table></figure></li><li><p>添加VMkernel端口，名称为iSCSI，</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm">创建标准交换机，绑定vmnic2网卡，配置<span class="hljs-built_in">IP</span>地址<span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">200</span>.<span class="hljs-number">100</span>。<br></code></pre></td></tr></table></figure></li></ol><ol start="6"><li><p>在本机安装的Starwind中创建一个20GB的iSCSI目标。</p></li><li><p>在ESXi中添加iSCSI软件适配器，绑定VMkernel端口iSCSI，使用动态方式添加iSCSI目标服务器。</p></li><li><p>在ESXi中添加存储器，使用新发现的iSCSI目标，格式化为VMFS-5文件系统，使用全部空间，存储名称为iSCSI-Starwind。</p></li><li><p>将CentOS的安装光盘ISO上传到存储iSCSI-Starwind。</p></li><li><p>在ESXi中创建虚拟机CentOS，放在存储iSCSI-Starwind上，内存为1GB。安装操作系统，将IP地址配置为192.168.80.200&#x2F;24，安装完成后，从本机ping虚拟机CentOS的IP地址。</p></li></ol><h3 id="准备虚拟机顺序"><a href="#准备虚拟机顺序" class="headerlink" title="准备虚拟机顺序"></a>准备虚拟机顺序</h3><p>1） 创建虚拟机</p><p>2） 安装操作系统</p><p>3） 安装vmtools</p><p>4） 打补丁</p><h3 id="vCenter-虚拟化平台"><a href="#vCenter-虚拟化平台" class="headerlink" title="vCenter 虚拟化平台"></a><strong>vCenter 虚拟化平台</strong></h3><ol><li><p>创建一台windows2008 datacenter r2的虚拟机，配置网络为nat，ip地址192.168.220.100，在上面安装vCenter</p></li><li><p>创建两台虚拟机，分别安装 ESXi 主机，在 VMware Workstation 中为 ESXi 主机按顺序添加四块网卡,分别是vmnet8 NAT模式、vmnet1 仅主机模式、vmnet2仅主机模式、vmnet0桥接模式，将管理网络的vmnet8网卡设置为192.168.136.11和192.168.136.12</p></li><li><p>创建一台windows2008 datacenter r2虚拟机，在上面安装starwind，配置iscsi，网络为vmnet1，ip地址为192.168.189.50</p></li><li><p>在vCenter主机中，创建数据中心DC，并添加主机192.168.136.和192.168.136.12</p></li><li><p>配置两台 ESXi 连接到 iSCSI 网络共享存储</p></li><li><p>使用共享存储创建虚拟机（centos7最小化安装），配置虚拟机网卡到vmnet0，桥接模式</p></li><li><p>安装完成后将虚拟机转换为模板，并从模板部署到一台esxi上</p></li><li><p>配置 VMkernel 接口支持 vMotion</p></li><li><p>迁移正在运行的虚拟机</p></li><li><p>在数据中心 DC 的右键菜单中选择新建群集Network Center</p></li><li><p>设置 VMware EVC</p></li><li><p>将 ESXi 主机 192.168.136.11 和 192.168.136.12 拖动到群集 Network Center 中</p></li><li><p>在群集 Network Center 的右键菜单中选择编辑设置，在群集功能中勾选“打开 vSphere DRS</p></li><li><p>打开 vSphere Client，在群集 Network Center 的右键菜单中选择编辑设置。在群集功能</p></li></ol><p>处勾选“打开 vSphere HA”，点击确定。</p><h3 id="vSphere的安装（30分最后大题）"><a href="#vSphere的安装（30分最后大题）" class="headerlink" title="vSphere的安装（30分最后大题）"></a>vSphere的安装（30分最后大题）</h3><p>实验指导书所有的<u>网络拓扑图</u>（十几分）<u>步骤</u>（十几分）（共4网络）（1.1~2.6）</p><p><strong>一、安装 ESXi 服务器</strong></p><p><img src="/img/image-20220614202336908.png" alt="image-20220614202336908"></p><p><strong>二、管理 VMware 虚拟网络</strong></p><p><img src="/img/image-20220614202358585.png" alt="image-20220614202358585"></p><p><strong>三、配置 iSCSI 目标服务器</strong></p><p><img src="/img/image-20220614202418845.png" alt="image-20220614202418845"></p><p><strong>四、配置 ESXi 使用 iSCSI 共享存储</strong></p><p><img src="/img/image-20220614202438030.png" alt="image-20220614202438030"></p><p><strong>五、安装 vCenter Server</strong></p><p><img src="/img/image-20220614202456913.png" alt="image-20220614202456913"></p><p><strong>ESXi iSCSI的配置</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>) 在VMware Workstation的虚拟网络编辑器中，添加vmnet2虚拟网络，类型为仅主机模式。将vmnet1、vmnet2、vmnet8的网段分别设置为<span class="hljs-number">192.168.100.0</span>/<span class="hljs-number">24</span>、<span class="hljs-number">192.168.200.0</span>/<span class="hljs-number">24</span>、<span class="hljs-number">192.168.80.0</span>/<span class="hljs-number">24</span>。<br><span class="hljs-attribute">2</span>) 创建VMware ESXi虚拟机，内存为<span class="hljs-number">4</span>GB，为虚拟机配置<span class="hljs-number">3</span>个网卡，网络类型分别为仅主机模式、NAT模式、vmnet2模式。<br><span class="hljs-attribute">3</span>) 安装VMware ESXi <span class="hljs-number">5</span>.<span class="hljs-number">5</span>，将管理网络的IP地址配置为<span class="hljs-number">192.168.100.100</span>（仅主机模式）<br><span class="hljs-attribute">4</span>) 使用vSphere Client连接到ESXi，添加虚拟机端口组ForVM，创建标准交换机，绑定vmnic1网卡。<br><span class="hljs-attribute">5</span>) 添加VMkernel端口，名称为iSCSI，创建标准交换机，绑定vmnic2网卡，配置IP地址<span class="hljs-number">192.168.200.100</span>。<br><span class="hljs-attribute">6</span>) 在本机安装的Starwind中创建一个<span class="hljs-number">20</span>GB的iSCSI目标。<br><span class="hljs-attribute">7</span>) 在ESXi中添加iSCSI软件适配器，绑定VMkernel端口iSCSI，使用动态方式添加iSCSI目标服务器。<br><span class="hljs-attribute">8</span>) 在ESXi中添加存储器，使用新发现的iSCSI目标，格式化为VMFS-<span class="hljs-number">5</span>文件系统，使用全部空间，存储名称为iSCSI-Starwind。<br><span class="hljs-attribute">9</span>) 将CentOS的安装光盘ISO上传到存储iSCSI-Starwind。<br><span class="hljs-attribute">10</span>) 在ESXi中创建虚拟机CentOS，放在存储iSCSI-Starwind上，内存为<span class="hljs-number">1</span>GB。安装操作系统，将IP地址配置为<span class="hljs-number">192.168.80.200</span>/<span class="hljs-number">24</span>，安装完成后，从本机ping虚拟机CentOS的IP地址。<br><br></code></pre></td></tr></table></figure><h3 id="KVM"><a href="#KVM" class="headerlink" title="KVM"></a><strong>KVM</strong></h3><p>类似VMware workstation，可以虚拟化安装windows也可以装Linux</p><h3 id="OpenStack"><a href="#OpenStack" class="headerlink" title="OpenStack"></a><strong>OpenStack</strong></h3><p><strong>Keystone&#x2F;Nova&#x2F;Glance&#x2F;Cinder&#x2F;Swift&#x2F;Neutron</strong></p><p>Keystone</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">为OpenStack上的所有服务提供身份认证和授权<br></code></pre></td></tr></table></figure><p>Nova</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">是OpenStack的控制器，支持OpenStack云内的实例的生命周期所需的所有活动处理。Nova作为管理平台管理着OpenStack云里的计算资源和扩展需求。<br></code></pre></td></tr></table></figure><p>Glance</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">提供了一个虚拟磁盘镜像的目录和存储仓库，可以提供对虚拟机镜像的存储和检索。这些磁盘镜像广泛应用于Nova组件之中。Glance能进行多个数据中心的镜像管理和租户私有镜像管理。<br></code></pre></td></tr></table></figure><p>Cinder</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">Cinder组件为虚拟机实例提供了块存储设备，同时为管理存储设备提供了一整套方法<br></code></pre></td></tr></table></figure><p>Swift</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">提供对象存储服务，允许对文件进行存储或者检索，但不通过挂载文件服务器上目录的方式来实现。Swift为OpenStack提供了分布式的、最终一致的虚拟对象存储。<br></code></pre></td></tr></table></figure><p>Neutron</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">是OpenStack中提供网络服务的核心组件，基于软件定义网络的思想，实现软件化的网络资源管理，在实现上充分利用了Linux操作系统中各种网络相关技术，支持第三方插件。<br></code></pre></td></tr></table></figure><p>OpenStack的各个服务之间通过统一的REST风格的API调用，实现系统的<strong>松耦合</strong></p><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a><strong>容器</strong></h3><p>Docker：</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mel">容器<span class="hljs-keyword">container</span>、镜像<span class="hljs-keyword">image</span>、仓库repository<br></code></pre></td></tr></table></figure><p>Docker使用沙箱(sandbox)机制，用的namespace实现应用系统之间的隔离</p><p>Docker是开源项目</p><h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h3><p>Docker</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">是一个开源的应用容器引擎，开发者可以打包他们的应用及依赖(dependency)到一个可移植的容器中，发布到流行的Linux机器上，也可实现虚拟化。<br>Docker is <span class="hljs-keyword">an</span> <span class="hljs-built_in">open</span> source containerization <span class="hljs-built_in">platform</span>. It enables developers <span class="hljs-built_in">to</span> package applications <span class="hljs-keyword">into</span> containers—standardized executable components combining application source code <span class="hljs-keyword">with</span> <span class="hljs-keyword">the</span> operating <span class="hljs-keyword">system</span> (OS) libraries <span class="hljs-keyword">and</span> dependencies required <span class="hljs-built_in">to</span> run that code <span class="hljs-keyword">in</span> <span class="hljs-keyword">any</span> environment. Containers simplify delivery <span class="hljs-keyword">of</span> distributed applications, <span class="hljs-keyword">and</span> have become increasingly popular <span class="hljs-keyword">as</span> organizations shift <span class="hljs-built_in">to</span> cloud-native development <span class="hljs-keyword">and</span> hybrid multicloud environments.<br></code></pre></td></tr></table></figure><p>Kubernetes</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs">是一个开源的容器集群管理系统，可以实现容器集群的<br>自动化部署、自动化扩缩容量、维护等功能。<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>PicPick Professional 6.3.0 Multilingual</title>
    <link href="/2022/08/09/PicPick-Professional-6-3-0-Multilingual/"/>
    <url>/2022/08/09/PicPick-Professional-6-3-0-Multilingual/</url>
    
    <content type="html"><![CDATA[<p><img src="https://sanet.pics/storage-8/0622/xAZd29OgvKR5eZKLzxJeBgoOUzmakKEo.png" alt="PicPick Professional 6.3.0 Multilingual"></p><p>File size: 62.3 MB</p><p>PicPick - all-in-one design tool for everyone. A full-featured screen capture tool, Intuitive image editor, color picker, color palette, pixel-ruler, protractor, crosshair, whiteboard and more. User friendly and full of features for creating your image. Suitable for software developers, graphic designers and home users.</p><p><strong>Capture anything</strong><br>Take screenshots of an entire screen, an active window, the scrolling windows and any specific region of your desktop, etc.</p><p><strong>Edit your images</strong><br>Annotate and highlight your images: text, arrows, shapes and more with the built-in image editor that includes the latest Ribbon style menu.</p><p><strong>Enhance with effects</strong><br>Easily add effects to your images: drop shadows, frames, watermarks, mosaic, motion blur, brightness control and more.</p><p><strong>Share everywhere</strong><br>Save, share, or send your images via Web, email, ftp, Dropbox, Google Drive, SkyDrive, Box, Evernote, Facebook, Twitter and more.</p><p><strong>Graphic Accessories</strong><br>Variety of graphic design accessories including color picker, color palette, pixel ruler, protractor, crosshair, magnifier, whiteboard.</p><p><strong>Customizable setting</strong><br>With highly advanced settings, you can customize hotkeys, file naming, image quality, and many other options that fits your needs.</p><p><a href="https://anonymz.com/?https://picpick.app/en/download/">What’s new</a></p><p><strong>Available On:</strong> Windows 11, 10, 8.1, 8, 7, Vista and XP including both 32-bit and 64-bit versions.</p><p>HOMEPAGE</p><p><a href="https://anonymz.com/?https://picpick.app/">https://anonymz.com/...://picpick.app/</a></p><p>DOWNLOAD FROM FREE FILE STORAGE</p><table><thead><tr><th><a href="https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar">https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar</a></th></tr></thead><tbody><tr><td><a href="https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3">https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3</a></td></tr></tbody></table>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>期末复习</title>
    <link href="/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <url>/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>Hadoop的核心结构HDFS, MapReduce ，YARN<br>Hadoop的安装<br>5个配置文件 core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml workers<br>启动<br>start-dfs.sh<br>start-yarn.sh</p><p>jps查看进程<br>NameNode：它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。<br>SecondaryNameNode：它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。<br>DataNode：它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。<br>ResourceManager（JobTracker）：JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。<br>NodeManager：（TaskTracker）执行任务。</p><p>怎么格式化<br>hadoop namenode -foramt<br>文件上传的指令 </p><ol><li><p>Command-line方式<br>hadoop fs -put &#x2F;xxx &#x2F;xxxx</p></li><li><p>用API来上传</p></li></ol><p>Configuration conf &#x3D; new Configuration();<br>conf.set(“fs. defaultFS”,” hdfs:&#x2F;&#x2F;hadoop201:8020”);<br>FileSystem fs &#x3D; FileSystem.get(conf);<br>Path srcPath &#x3D; new Path(“xxx”);<br>Path dstPath &#x3D; new Path(“xxx”);<br>fs.copyFromLocalFile (srcPath, dstPath);<br>fs.close();</p><p>HDFS的读写机制<br>写</p><ol><li>客户端通过FileSystem向NameNode请求上传文件</li><li>NameNode检查目标地址，是否存在，目录是否存在，确认是否可以上传</li><li>NameNode告诉客户端你要怎么去分割文件</li><li>客户端请求第一个block上传到哪几个DataNode</li><li>NameNode返回DataNode节点 </li><li>客户端通过FSDataOutputStream请求向指定DataNode节点上传数据，</li><li>比如副本数量有3个，只传一个节点，然后由这个节点再传给其他2个副本节点</li><li>client-&gt;dn1-&gt;dn2-&gt;dn3，客户端第一个数据包发送到dn1后，dn1就会往dn2写</li><li>dn2写完第一个就会往dn3传</li></ol><p>读</p><ol><li>客户端通过FileSystem向NameNode请求下载文件</li><li>NameNode查询Metadata，找到请求的文件在哪个Datanode上</li><li>NameNode挑选出一台DataNode（就近原则）,请求读取数据</li><li>DataNode开始传输数据给客户端，流的方式</li><li>客户端以包为单位接收，先存到本地缓存，然后再写到目标文件</li></ol><p>MapReduce的优缺点<br>优点：</p><ol><li><p>高可靠HA High Available<br>数据会被自动保存为多个副本（默认3个），提高了容错性，坏了一个可以自动回复</p></li><li><p>提高IO性能<br>原理类似raid，一个硬盘的IO吞吐能力是有限的，多副本存在，可以高并发</p></li><li><p>适合处理大数据<br>数据规模很大的时候，GB TB PB</p></li><li><p>物美价廉<br>EMC存储,Oracle数据库,IBM服务器   去IOE<br>普通的廉价服务器，通过多副本机制，提高可靠性，就便宜了</p></li></ol><p>缺点：</p><ol><li><p>不适合低延迟数据访问<br>本地100m 1秒读完，1TB文件，本机10000秒读完，<br>hdfs 100m 连接10s 调配10s 读取1s  21 1TB  连接10s 调配10s 读取3000s<br>只适合较大数据的分析，存取</p></li><li><p>无法高效处理小文件<br>namenode管理小文件会耗费大量内存和存储信息</p></li><li><p>写入并发处理不好，修改支持不好<br>支持追加数据，随机修改不支持</p></li><li><p>不擅长DAG</p></li></ol><p>MapReduce工作流程(看图记住)<br> 执行都是Job<br>MapTask (shuffle)  ReduceTask<br>Combiner</p><p>MapReduce编程<br>Mapper怎么写<br>Reducer怎么写<br>Job 怎么写</p><ol><li>去重</li><li>计数 wordcount</li><li>统计总分，均分</li><li>好友推荐</li><li>排序</li><li>表的合并</li></ol><p>Hive是什么<br>给你几张表会写sql语句查询<br>id     月份    次数<br>1001   2020-1  1<br>1002   2020-2  3<br>1001   2020-2  5<br>1003   2020-3  6<br>1002   2020-10  3<br>1003   2020-4  1<br>1001   2020-3  2<br>1001   2020-4  1<br>1002   2020-11  2<br>1004   2020-10  4</p><p>统计用户累计访问次数，和单月最大次数</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Coding_Is_Fun</title>
    <link href="/2022/08/09/Coding-Is-Fun/"/>
    <url>/2022/08/09/Coding-Is-Fun/</url>
    
    <content type="html"><![CDATA[<p>About 137,000,000 results (0.51 seconds) </p><h1 id="Search-Results"><a href="#Search-Results" class="headerlink" title="Search Results"></a>Search Results</h1><h2 id="Local-Time"><a href="#Local-Time" class="headerlink" title="Local Time"></a>Local Time</h2><p>Hong Kong Standard Time</p><p>Time zone in Hong Kong (GMT+8)</p><p>Tuesday, August 9, 2022, 4:17 PM</p><p><a href="https://www.google.com/search?q=time+zone+hong+kong&oq=time+zone+hong+kong&aqs=chrome..69i57j0i131i395i433i512j0i395i402l2j0i395i433i457i512j0i131i433i512j0i512j0i131i433i512j0i512j0i131i433i512.4160j1j7&sourceid=chrome&ie=UTF-8#">Feedback</a></p><h3 id="People-also-ask"><a href="#People-also-ask" class="headerlink" title="People also ask"></a>People also ask</h3><p>What time zone does Hong Kong use?</p><p>Is Hong Kong Time GMT?</p><p>Is Hong Kong on China Standard Time?</p><p>How far ahead is Hong Kong Time?</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>

<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  <title>The World to Affluence</title>
  <meta name="author" content="Admin">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="The World to Affluence"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

  <!--[if lt IE 9]><script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script><![endif]-->
  

<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">The World to Affluence</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/null">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article id="post-kuroda-seiki" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T16:32:07.000Z"><a href="/2022/08/10/kuroda-seiki/">2022-08-10</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/10/kuroda-seiki/">Kuroda Seiki</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p><img src="/img/image-20220810003244150.png" alt="image-20220810003244150"></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kazoku">Viscount</a> <strong>Kuroda Seiki</strong> (黒田 清輝, August 9, 1866 – July 15, 1924) was a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Japanese_people">Japanese</a> painter and teacher, noted for bringing Western art theory and practice to a wide Japanese audience.</p>
<p>He was among the leaders of the <em><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Y%C5%8Dga">yōga</a></em> (or Western-style) movement in late 19th and early 20th-century <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Japanese_painting">Japanese painting</a>, and has come to be remembered in Japan as “the father of Western-style painting.”</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-flume" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T12:53:54.000Z"><a href="/2022/08/09/flume/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/flume/">Flume 学习笔记</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h1 id><a href="#" class="headerlink" title></a></h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Flume 是一种分布式、可靠且可用的服务，用于高效收集、聚合和移动大量日志数据。它具有基于流数据流的简单灵活的架构。它具有可调整的可靠性机制以及许多故障转移和恢复机制，具有健壮性和容错性。它使用简单可扩展数据模型允许在线分析应用程序。</p>
<p><img src="/img/DevGuide_image00.png" alt="Agent component diagram"></p>
<p>实时读取服务器上的日志数据，将数据写入到HDFS</p>
<h3 id="Flume的优点"><a href="#Flume的优点" class="headerlink" title="Flume的优点"></a>Flume的优点</h3><ol>
<li><p>可以和任意存储进程集成</p>
</li>
<li><p>输入的数据速率大于写入目的的存储速率，Flume会进行缓冲，减小hdfs的压力</p>
</li>
<li><p>flume中在channel上支持事务，使用了两个事务模型(sender + reciever)，确保消息可靠发送</p>
<p>source-&gt;channel 和channel-&gt;sink ，只有事务中的所有的数据全部提交到channel，那么source才认为数据读取完成，同理，只有所有数据都别写出sink，才会从channel中移除</p>
</li>
</ol>
<h3 id="Flume的架构"><a href="#Flume的架构" class="headerlink" title="Flume的架构"></a>Flume的架构</h3><p><strong>Source</strong> 数据输入端的类型: </p>
<p>Avro Source<br>Thrift Source<br>Exec Source<br>JMS Source<br>JMS message converter<br>SSL and JMS Source<br>Spooling Directory Source<br>Event Deserializers<br>LINE<br>AVRO<br>BlobDeserializer<br>Taildir Source<br>Twitter 1% firehose Source (experimental)<br>Kafka Source<br>NetCat TCP Source<br>NetCat UDP Source<br>Sequence Generator Source<br>Syslog Sources<br>Syslog TCP Source<br>Multiport Syslog TCP Source<br>Syslog UDP Source<br>HTTP Source<br>JSONHandler<br>BlobHandler<br>Stress Source<br>Legacy Sources<br>Avro Legacy Source<br>Thrift Legacy Source<br>Custom Source<br>Scribe Source</p>
<p><strong>Sink</strong> 目的地的类型：</p>
<p>HDFS Sink<br>Hive Sink<br>Logger Sink<br>Avro Sink<br>Thrift Sink<br>IRC Sink<br>File Roll Sink<br>Null Sink<br>HBaseSinks<br>HBaseSink<br>HBase2Sink<br>AsyncHBaseSink<br>MorphlineSolrSink<br>ElasticSearchSink<br>Kite Dataset Sink<br>Kafka Sink<br>HTTP Sink<br>Custom Sink</p>
<p><strong>Channel</strong> 是source sink之间的缓冲，类型有:</p>
<p>Memory Channel : 基于内存的，你不关心日志是否丢失<br>JDBC Channel<br>Kafka Channel<br>File Channel ：保证数据不丢失，写入channel的数据会被持久化<br>Spillable Memory Channel<br>Pseudo Transaction Channel<br>Custom Channel</p>
<h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><ol>
<li><p>下载地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://flume.apache.org/download.html</span><br></pre></td></tr></table></figure>
</li>
<li><p>上传到&#x2F;opt&#x2F;software下</p>
</li>
<li><p>解压缩，记得切换到hadoop用户</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
</li>
<li><p>做软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s apache-flume-1.9.0-bin flume</span><br></pre></td></tr></table></figure>
</li>
<li><p>移除有冲突的jar包</p>
<p>将guava-11.0.2.jar包移除，或者改名也行</p>
<p>因为和hadoop下的冲突</p>
<p>&#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;guava-27.0-jre.jar</p>
<p>可以把上面的新的cp过来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /opt/module/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /opt/module/flume/lib/</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例一-监控本地端口"><a href="#案例一-监控本地端口" class="headerlink" title="案例一: 监控本地端口"></a>案例一: 监控本地端口</h2><p>NetCat TCP</p>
<p>使用Flume监听一个端口，收集这个端口的数据，打印到控制台，或者输出到文件</p>
<ol>
<li><p>下载安装netcat</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y nc</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置flume的配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir jobs</span><br><span class="line">vi flume-nc.conf</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line"># a1 是agent的名字，随便起，后面启动flume的时候要对应这个名字</span><br><span class="line"># r1 是source的名字</span><br><span class="line">a1.sources = r1</span><br><span class="line"># k1是sink的名字</span><br><span class="line">a1.sinks = k1</span><br><span class="line"># c1是channel的名字</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line"># 配置source</span><br><span class="line"># r1的类型是netcat</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line"># 绑定的ip地址是localhost</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line"># 绑定的端口是44444</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line"># 配置 sink</span><br><span class="line"># sink的类型是日志类型</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line"># 把 source和sink 跟channel 连接起来</span><br><span class="line"># r1的channel是c1</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line"># k1的channel是c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查端口是否被占用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -nlp | grep 44444</span><br><span class="line"></span><br><span class="line">tcp6       0      0 127.0.0.1:44444         :::*                    LISTEN      22600/java  </span><br></pre></td></tr></table></figure>

<p>上面就是44444端口被一个java进程占用，进程id是22600</p>
<p>杀掉进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill 22600</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动flume</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ bin/flume-ng agent --conf conf --conf-file jobs/flume-nc.conf --name 	a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">--conf conf 配置文件在什么地方，跟的是个目录</span><br><span class="line">--conf-file flume本次运行的配置文件(source sink channel的配置)</span><br><span class="line">--name agent的名字</span><br><span class="line">-Dflume.root.logger=INFO,console 运行时参数flume.root.logger修改为INFO,console，让日志在控制台输出，输出的级别是INFO，日志级别DEBUG INFO WARN ERROR</span><br><span class="line"></span><br><span class="line">简写</span><br><span class="line">bin/flume-ng agent -c conf -n a1 -f jobs/flume-nc.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动nc发送数据</p>
<p>打开另外一个远程连接窗口执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc localhost 44444</span><br></pre></td></tr></table></figure>

<p>输入内容</p>
<p>在flume运行的窗口就会收到信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line"></span><br><span class="line">2022-04-21 22:59:31,374 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: E4 BD 95 E5 85 B5 E5 AE B6                      ......... &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例二：实时监控单个文件，保存到hdfs中"><a href="#案例二：实时监控单个文件，保存到hdfs中" class="headerlink" title="案例二：实时监控单个文件，保存到hdfs中"></a>案例二：实时监控单个文件，保存到hdfs中</h2><ol>
<li><p>配置下hdfs</p>
<p>之前的服务器已经配好了&#x2F;etc&#x2F;profiled.d&#x2F;hadoop_env.sh</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_202</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line"># HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>创建flume配置文件</p>
<p>jobs&#x2F;flume-file-hdfs.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line"># 命令是tail -F</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/njust.log</span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/flume/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/flume-ng agent -c conf -n a1 -f jobs/flu-file-hdfs.conf </span><br></pre></td></tr></table></figure>

<p>往&#x2F;tmp&#x2F;njust.log里面加东西</p>
<p> 观察hdfs的目录</p>
</li>
</ol>
<h2 id="案例三-实时监控目录"><a href="#案例三-实时监控目录" class="headerlink" title="案例三: 实时监控目录"></a>案例三: 实时监控目录</h2><p>只监控目录下的新文件，.complete就不管了</p>
<ol>
<li><p>配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source spooldir 监控目录的source</span><br><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line"># 配置监控目录</span><br><span class="line">a1.sources.r1.spoolDir = /tmp/hadoop</span><br><span class="line"># 是否添加文件绝对路径当文件头</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line"># 文件上传好以后，会被改名，后缀是什么</span><br><span class="line">a1.sources.r1.fileSuffix = .COMPLETED</span><br><span class="line"># includePattern 可以用正则表达式来配置哪些文件名的文件要上传</span><br><span class="line"># ignorePattern 哪些忽略</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/flume/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"># 多久生成一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.rollInterval = 60</span><br><span class="line"># 一次写100个Event到hdfs</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>


</li>
<li><p>运行</p>
</li>
</ol>
<h2 id="案例四-实时监控目录下多个文件追加"><a href="#案例四-实时监控目录下多个文件追加" class="headerlink" title="案例四 实时监控目录下多个文件追加"></a>案例四 实时监控目录下多个文件追加</h2><p>exec source 是一个文件</p>
<p>Taildir source 适用监听多个追加文件，而且支持断点续传</p>
<ol>
<li><p>配置flume-taildir-hdfs.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source taildir 监控目录下的多个文件追加</span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.positionFile = /tmp/hadoop/flume/taildir_position.json</span><br><span class="line"># 指示有几个文件组，中间用空格分开</span><br><span class="line">a1.sources.r1.filegroups = f1 f2</span><br><span class="line"># 定义f1文件组的文件，可以是单个文件</span><br><span class="line">a1.sources.r1.filegroups.f1 = /tmp/hadoop/test1/example.log</span><br><span class="line">a1.sources.r1.headers.f1.headerKey1 = value1</span><br><span class="line">a1.sources.r1.filegroups.f2 = /tmp/hadoop/test2/.*log.*</span><br><span class="line">a1.sources.r1.headers.f2.headerKey1 = value2</span><br><span class="line">a1.sources.r1.headers.f2.headerKey2 = value2-2</span><br><span class="line"># 日志里面用文件的绝对路径做头</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line">a1.sources.ri.maxBatchCount = 1000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/flume/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"># 多久生成一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.rollInterval = 60</span><br><span class="line"># 一次写100个Event到hdfs</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Flume-事务"><a href="#Flume-事务" class="headerlink" title="Flume 事务"></a>Flume 事务</h2><p>Flume agent中间有三个组件，source  channel  sink，里面流的东西是event ，event由head和body组成</p>
<p>事务分两个部分</p>
<h3 id="put事务"><a href="#put事务" class="headerlink" title="put事务"></a>put事务</h3><p>source -&gt; channel的部分 </p>
<p><img src="/img/FFFFFF-t_70_pic_center.png"></p>
<p>首先Source会采集一批数据，封装为event，缓存达到batch data的最大容量时（batch data的大小取决于配置参数batch size的值），Flume开启事务：</p>
<p>doPut（）:将这批event写入到临时缓冲区putList，putList是一个LinkedBlockingDeque<br>，大小取决于配置Channel的参数transaction capacity的大小。</p>
<p>doCommit（）:检查channel内存队列是否足够合并，内存队列的大小由Channel的capacity参数控制， Channel的容量内存队列足够的时候，提交event成功。</p>
<p>doRollback（）: channel内存队列空间不够时，回滚，这里会将整个putList中的数据都扔掉，然后给Source返回一个ChannelException异常，告诉Source数据没有采集上。Source会重新采集这批数据，然后开启新的事务。</p>
<h3 id="Take事务"><a href="#Take事务" class="headerlink" title="Take事务"></a>Take事务</h3><p>channel -&gt; sink </p>
<p><img src="/img/pic_center-16511116964952.png"></p>
<p>doTake（）：sink将数据剪切取到临时缓冲区takeList，takeList也是一个LinkedBlockingDeque，<br>大小取决于配置Channel的参数transaction capacity的大小，同时也拷贝一份放入写往HDFS的IO流中。</p>
<p>doCommit（）：如果event全部发送成功，就清除takeList。</p>
<p>doRollback（）：如果发送过程中出现异常，回滚，将takeList中的全部event归还给Channel。这个操作可能导致数据重复,如果已经写入一半的event到了HDFS，但是回滚时会向channel归还整个takeList中的event，后续再次开启事务向HDFS写入这批event时候，就出现了数据重复。</p>
<p>Flume的事务仅能保证两个传输阶段的数据不丢，但是如果channel选用的是memory channel，那么由于memory channel将数据存储在内存中，一旦channel发生异常，数据仍然可能丢失，但采用File channel时，数据传输到channel时会落盘，再结合事务，会保证整体上数据不会丢失，但是仍然可能会在take事务阶段发生数据重复。</p>
<h2 id="Flume-重要组件"><a href="#Flume-重要组件" class="headerlink" title="Flume 重要组件"></a>Flume 重要组件</h2><p><img src="/img/t_70_pic_center.png"></p>
<ol>
<li><p>Flume Channel Selectors ( 3 种 )</p>
<p>作用就是选出event该去哪个channel，默认就是replicating（复制）</p>
<p>Replicating Channel Selector</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2 c3</span><br><span class="line"># 定义channel的选择器是复制, 将source来的一个event  c1 c2 c3都复制发一份</span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line"># 定义了3个channel</span><br><span class="line">a1.sources.r1.channels = c1 c2 c3</span><br><span class="line"># c3如果数据出问题，不管，c1 c2没配置，则必须执行事务</span><br><span class="line">a1.sources.r1.selector.optional = c3</span><br></pre></td></tr></table></figure>

<p>Multiplexing Channel Selector</p>
<p>会将event根据条件发到不同的channel</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2 c3 c4</span><br><span class="line">a1.sources.r1.selector.type = multiplexing</span><br><span class="line">a1.sources.r1.selector.header = state</span><br><span class="line">a1.sources.r1.selector.mapping.CZ = c1</span><br><span class="line">a1.sources.r1.selector.mapping.US = c2 c3</span><br><span class="line">a1.sources.r1.selector.default = c4</span><br></pre></td></tr></table></figure></li>
</ol>
<p>​		Custom Channel Selector  自定义的</p>
<p>​		implementation of the ChannelSelector interface</p>
<ol start="2">
<li><p>Flume Sink Processors</p>
<p>Default Sink Processor：对应单个sink</p>
<p>Failover Sink Processor: 维护一个有优先级的水池列表，确保 event一定会被处理（送达）,失败的会处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br><span class="line"># 必配 sink优先级，数字越大优先级越高</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 5</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 10</span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br></pre></td></tr></table></figure>

<p>Load balancing Sink Processor：实现负载均衡sinks</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.backoff = true</span><br><span class="line">a1.sinkgroups.g1.processor.selector = random</span><br></pre></td></tr></table></figure>


</li>
<li><p>Flume Interceptors</p>
<p>flume在执行中有能力去修改和丢弃event，Interceptors拦截器就是做这个的</p>
</li>
</ol>
<h2 id="Flume的拓扑结构"><a href="#Flume的拓扑结构" class="headerlink" title="Flume的拓扑结构"></a>Flume的拓扑结构</h2><ol>
<li><p>串联</p>
<p><img src="/img/UserGuide_image03.png" alt="Two agents communicating over Avro RPC"></p>
</li>
</ol>
<p>​      将多个flume按顺序连接起来，不建议串联太长，因为如果中间一个出问题，整个通道就都完了</p>
<ol start="2">
<li>Consolidation 合并</li>
</ol>
<p><img src="/img/UserGuide_image02.png" alt="A fan-in flow using Avro RPC to consolidate events in one place"></p>
<p>​        大多数情况用这种，工作环境，服务器会非常多，将多个服务器的数据采集汇总，给每台服务器配一个flume，然后传送到一个统一的sink去汇总处理，日志分析</p>
<ol start="3">
<li>Multiplexing the flow 多路复用</li>
</ol>
<p><img src="/flume.assets/UserGuide_image01.png" alt="A fan-out flow using a (multiplexing) channel selector"></p>
<p>​      支持将source分发到不同的channel，多个目的地</p>
<ol start="4">
<li><p>Load-Balance负载均衡和Failover 故障切换</p>
<p><img src="/img/t_70_pic_center-16511166368648.png"></p>
</li>
</ol>
<p>将多个sink 组成一个组，sink组实现负载均衡和故障切换</p>
<h2 id="案例五-多路"><a href="#案例五-多路" class="headerlink" title="案例五 多路"></a>案例五 多路</h2><p>有一个FlumeA监控文件，会把变动发到FlumeB，FlumeB负责写入hdfs，FlumeA还会发送给FlumeC，FlumeC就直接输出到本地console或者文件</p>
<p><img src="/img/image-20220428115518751-165111812064810.png" alt="image-20220428115518751"></p>
<ol>
<li><p>配置文件 flume-file-flume.conf 用来将日志的内容发送到2个channel，两个sink</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line"># 配置 selector</span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/njust.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># 配置sink k1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop201</span><br><span class="line">a1.sinks.k1.port = 4545</span><br><span class="line"># 配置sink k2</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop201</span><br><span class="line">a1.sinks.k2.port = 4646</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># c2的类型是memory channel</span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line"># c2最多能容纳1000个event</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line"># c2的事务提交100个提交一次</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置文件 flume-flume-hdfs.conf 从flume到hdfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.channels = c3</span><br><span class="line">a2.sinks = k3</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a2.sources.r2.type = avro</span><br><span class="line">a2.sources.r2.bind = hadoop201</span><br><span class="line">a2.sources.r2.port = 4545</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a2.sinks.k3.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a2.sinks.k3.hdfs.path = hdfs://hadoop201:8020/flume/events2/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a2.sinks.k3.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a2.sinks.k3.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a2.sinks.k3.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a2.sinks.k3.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a2.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c3的类型是memory channel</span><br><span class="line">a2.channels.c3.type = memory</span><br><span class="line"># c3最多能容纳1000个event</span><br><span class="line">a2.channels.c3.capacity = 1000</span><br><span class="line"># c3的事务提交100个提交一次</span><br><span class="line">a2.channels.c3.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a2.sources.r2.channels = c3</span><br><span class="line">a2.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure>


</li>
<li><p>配置文件 flume-flume-local.conf 从flume到本地</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a3.sources = r3</span><br><span class="line">a3.channels = c4</span><br><span class="line">a3.sinks = k4</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a3.sources.r3.type = avro</span><br><span class="line">a3.sources.r3.bind = hadoop201</span><br><span class="line">a3.sources.r3.port = 4646</span><br><span class="line"></span><br><span class="line"># 配置sink file roll sink</span><br><span class="line">a3.sinks.k4.type = file_roll</span><br><span class="line"># 不会自动建目录，请一定要提前建好目录</span><br><span class="line">a3.sinks.k4.sink.directory = /tmp/hadoop/flume/logs</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c4的类型是memory channel</span><br><span class="line">a3.channels.c4.type = memory</span><br><span class="line"># c4最多能容纳1000个event</span><br><span class="line">a3.channels.c4.capacity = 1000</span><br><span class="line"># c4的事务提交100个提交一次</span><br><span class="line">a3.channels.c4.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a3.sources.r3.channels = c4</span><br><span class="line">a3.sinks.k4.channel = c4</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例六-合并"><a href="#案例六-合并" class="headerlink" title="案例六 合并"></a>案例六 合并</h2><img src="/img/image-20220428145440550.png" alt="image-20220428145440550" style="zoom: 50%;">

<ol>
<li><p>配置a1 flume-file-avro.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/hadoop/test1/example.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># 配置sink k1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop203</span><br><span class="line">a1.sinks.k1.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置a2 flume-nc-avro.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.channels = c2</span><br><span class="line">a2.sinks = k2</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line"># r2的类型是netcat</span><br><span class="line">a2.sources.r2.type = netcat</span><br><span class="line"># 绑定的ip地址是localhost</span><br><span class="line">a2.sources.r2.bind = hadoop202</span><br><span class="line"># 绑定的端口是44444</span><br><span class="line">a2.sources.r2.port = 44444</span><br><span class="line"></span><br><span class="line"># 配置sink k2</span><br><span class="line">a2.sinks.k2.type = avro</span><br><span class="line">a2.sinks.k2.hostname = hadoop203</span><br><span class="line">a2.sinks.k2.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c2的类型是memory channel</span><br><span class="line">a2.channels.c2.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a2.channels.c2.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a2.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a2.sources.r2.channels = c2</span><br><span class="line">a2.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置a3 flume-avro-logger.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a3.sources = r3</span><br><span class="line">a3.channels = c3</span><br><span class="line">a3.sinks = k3</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a3.sources.r3.type = avro</span><br><span class="line">a3.sources.r3.bind = hadoop203</span><br><span class="line">a3.sources.r3.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置sink logger</span><br><span class="line">a3.sinks.k3.type = logger</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c3的类型是memory channel</span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line"># c3最多能容纳1000个event</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line"># c3的事务提交100个提交一次</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p>有时不能满足实际需求，需要自定义Source和Sink</p>
<h3 id="案例一：自定义Source"><a href="#案例一：自定义Source" class="headerlink" title="案例一：自定义Source"></a>案例一：自定义Source</h3><p>输出自定义的内容，然后在控制台用logger输出</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.edu.njust.flume;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Maps;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.EventDeliveryException;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.PollableSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.event.EventBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.source.AbstractSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> notre</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/5/4</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySource</span> <span class="keyword">extends</span> <span class="title class_">AbstractSource</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span>, PollableSource &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义的属性为将来在job文件中配置的属性</span></span><br><span class="line">  <span class="keyword">private</span> String content;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> delay;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 这个方法的作用就是在配置的配置文件中读属性</span></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    content = context.getString(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;今天天气真好&quot;</span>);</span><br><span class="line">    delay = context.getLong(<span class="string">&quot;delay&quot;</span>,<span class="number">2000L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      <span class="comment">// 创建一个空的头</span></span><br><span class="line">      Map&lt;String,String&gt; headMap = Maps.newHashMap();</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// 创建一个用来传递数据的Event</span></span><br><span class="line">        <span class="type">Event</span> <span class="variable">event</span> <span class="operator">=</span> EventBuilder.withBody(content+i, Charset.forName(<span class="string">&quot;UTF-8&quot;</span>),headMap);</span><br><span class="line">        <span class="comment">// 配置文件中配置了哪个channel连接到这个source，他就去拿哪个channel</span></span><br><span class="line">        getChannelProcessor().processEvent(event);</span><br><span class="line">        <span class="comment">// 休眠下（可以取消）</span></span><br><span class="line">        Thread.sleep(delay);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status.READY;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getBackOffSleepIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getMaxBackOffSleepInterval</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>idea如何打包</p>
<ol>
<li>先build module</li>
<li>在 project structure中添加一个artifact，配置为jar add–&gt;from modules with dependency</li>
<li>在右侧output layer中删除所有的dependency,保留Compile output的那个jar包</li>
</ol>
<p>在项目的out目录下找到打好的jar包</p>
<p>上传到flume下的lib目录下</p>
<p>修改jar包的权限<code>sodu chown hadoop:hadoop FlumeDemo.jar </code></p>
<p>配置jobs文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = cn.edu.njust.flume.MySource</span><br><span class="line">a1.sources.r1.content = hello</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -c conf -n a1 -f jobs/flume-mysource.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>



<h3 id="案例二：自定义Sink"><a href="#案例二：自定义Sink" class="headerlink" title="案例二：自定义Sink"></a>案例二：自定义Sink</h3><p>Sink一定要启动事务，从channel中拿取events，然后写入文件或者hdfs…</p>
<p>自定义一个Sink，监听netcat内容，加上前后缀，输出到Logger</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.edu.njust.flume;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Channel;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.EventDeliveryException;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Transaction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.sink.AbstractSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> notre</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/5/4</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySink</span> <span class="keyword">extends</span> <span class="title class_">AbstractSink</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LoggerFactory.getLogger(MySink.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String prefix;</span><br><span class="line">  <span class="keyword">private</span> String suffix;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    prefix = context.getString(<span class="string">&quot;prefix&quot;</span>,<span class="string">&quot;begin-&quot;</span>);</span><br><span class="line">    suffix = context.getString(<span class="string">&quot;suffix&quot;</span>, <span class="string">&quot;-end&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Channel</span> <span class="variable">ch</span> <span class="operator">=</span> getChannel();</span><br><span class="line">    Event event;</span><br><span class="line">    <span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> ch.getTransaction();</span><br><span class="line">    tx.begin();</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      event = ch.take();</span><br><span class="line">      <span class="keyword">if</span>(event!=<span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      LOGGER.info(prefix+ <span class="keyword">new</span> <span class="title class_">String</span>(event.getBody())+suffix);</span><br><span class="line">      tx.commit();</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">      tx.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status.READY;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = cn.edu.njust.flume.MySink</span><br><span class="line">a1.sinks.k1.prefix = njust-</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f jobs/flume-mysink.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-virtualizatoin-and-cloud-computing-final-exam-preparation" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T12:20:08.000Z"><a href="/2022/08/09/virtualizatoin-and-cloud-computing-final-exam-preparation/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/virtualizatoin-and-cloud-computing-final-exam-preparation/">virtualizatoin_and_cloud_computing_final_exam_preparation</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-PicPick-Professional-6-3-0-Multilingual" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T09:42:22.000Z"><a href="/2022/08/09/PicPick-Professional-6-3-0-Multilingual/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/PicPick-Professional-6-3-0-Multilingual/">PicPick Professional 6.3.0 Multilingual</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p><img src="https://sanet.pics/storage-8/0622/xAZd29OgvKR5eZKLzxJeBgoOUzmakKEo.png" alt="PicPick Professional 6.3.0 Multilingual"></p>
<p>File size: 62.3 MB</p>
<p>PicPick - all-in-one design tool for everyone. A full-featured screen capture tool, Intuitive image editor, color picker, color palette, pixel-ruler, protractor, crosshair, whiteboard and more. User friendly and full of features for creating your image. Suitable for software developers, graphic designers and home users.</p>
<p><strong>Capture anything</strong><br>Take screenshots of an entire screen, an active window, the scrolling windows and any specific region of your desktop, etc.</p>
<p><strong>Edit your images</strong><br>Annotate and highlight your images: text, arrows, shapes and more with the built-in image editor that includes the latest Ribbon style menu.</p>
<p><strong>Enhance with effects</strong><br>Easily add effects to your images: drop shadows, frames, watermarks, mosaic, motion blur, brightness control and more.</p>
<p><strong>Share everywhere</strong><br>Save, share, or send your images via Web, email, ftp, Dropbox, Google Drive, SkyDrive, Box, Evernote, Facebook, Twitter and more.</p>
<p><strong>Graphic Accessories</strong><br>Variety of graphic design accessories including color picker, color palette, pixel ruler, protractor, crosshair, magnifier, whiteboard.</p>
<p><strong>Customizable setting</strong><br>With highly advanced settings, you can customize hotkeys, file naming, image quality, and many other options that fits your needs.</p>
<p><a target="_blank" rel="noopener" href="https://anonymz.com/?https://picpick.app/en/download/">What’s new</a></p>
<p><strong>Available On:</strong> Windows 11, 10, 8.1, 8, 7, Vista and XP including both 32-bit and 64-bit versions.</p>
<p>HOMEPAGE</p>
<p><a target="_blank" rel="noopener" href="https://anonymz.com/?https://picpick.app/">https://anonymz.com/...://picpick.app/</a></p>
<p>DOWNLOAD FROM FREE FILE STORAGE</p>
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener" href="https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar">https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar</a></th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3">https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3</a></td>
</tr>
</tbody></table>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-期末复习" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T09:34:50.000Z"><a href="/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">期末复习</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>Hadoop的核心结构HDFS, MapReduce ，YARN<br>Hadoop的安装<br>5个配置文件 core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml workers<br>启动<br>start-dfs.sh<br>start-yarn.sh</p>
<p>jps查看进程<br>NameNode：它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。<br>SecondaryNameNode：它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。<br>DataNode：它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。<br>ResourceManager（JobTracker）：JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。<br>NodeManager：（TaskTracker）执行任务。</p>
<p>怎么格式化<br>hadoop namenode -foramt<br>文件上传的指令 </p>
<ol>
<li><p>Command-line方式<br>hadoop fs -put &#x2F;xxx &#x2F;xxxx</p>
</li>
<li><p>用API来上传</p>
</li>
</ol>
<p>Configuration conf &#x3D; new Configuration();	<br>conf.set(“fs. defaultFS”,” hdfs:&#x2F;&#x2F;hadoop201:8020”);<br>FileSystem fs &#x3D; FileSystem.get(conf);<br>Path srcPath &#x3D; new Path(“xxx”);<br>Path dstPath &#x3D; new Path(“xxx”);<br>fs.copyFromLocalFile (srcPath, dstPath);<br>fs.close();</p>
<p>HDFS的读写机制<br>写</p>
<ol>
<li>客户端通过FileSystem向NameNode请求上传文件</li>
<li>NameNode检查目标地址，是否存在，目录是否存在，确认是否可以上传</li>
<li>NameNode告诉客户端你要怎么去分割文件</li>
<li>客户端请求第一个block上传到哪几个DataNode</li>
<li>NameNode返回DataNode节点 </li>
<li>客户端通过FSDataOutputStream请求向指定DataNode节点上传数据，</li>
<li>比如副本数量有3个，只传一个节点，然后由这个节点再传给其他2个副本节点</li>
<li>client-&gt;dn1-&gt;dn2-&gt;dn3，客户端第一个数据包发送到dn1后，dn1就会往dn2写</li>
<li>dn2写完第一个就会往dn3传</li>
</ol>
<p>读</p>
<ol>
<li>客户端通过FileSystem向NameNode请求下载文件</li>
<li>NameNode查询Metadata，找到请求的文件在哪个Datanode上</li>
<li>NameNode挑选出一台DataNode（就近原则）,请求读取数据</li>
<li>DataNode开始传输数据给客户端，流的方式</li>
<li>客户端以包为单位接收，先存到本地缓存，然后再写到目标文件</li>
</ol>
<p>MapReduce的优缺点<br>优点：</p>
<ol>
<li><p>高可靠HA High Available<br>数据会被自动保存为多个副本（默认3个），提高了容错性，坏了一个可以自动回复</p>
</li>
<li><p>提高IO性能<br>原理类似raid，一个硬盘的IO吞吐能力是有限的，多副本存在，可以高并发</p>
</li>
<li><p>适合处理大数据<br>数据规模很大的时候，GB TB PB</p>
</li>
<li><p>物美价廉<br>EMC存储,Oracle数据库,IBM服务器   去IOE<br>普通的廉价服务器，通过多副本机制，提高可靠性，就便宜了</p>
</li>
</ol>
<p>缺点：</p>
<ol>
<li><p>不适合低延迟数据访问<br>本地100m 1秒读完，1TB文件，本机10000秒读完，<br>hdfs 100m 连接10s 调配10s 读取1s  21 1TB  连接10s 调配10s 读取3000s<br>只适合较大数据的分析，存取</p>
</li>
<li><p>无法高效处理小文件<br>namenode管理小文件会耗费大量内存和存储信息</p>
</li>
<li><p>写入并发处理不好，修改支持不好<br>支持追加数据，随机修改不支持</p>
</li>
<li><p>不擅长DAG</p>
</li>
</ol>
<p>MapReduce工作流程(看图记住)<br> 执行都是Job<br>MapTask (shuffle)  ReduceTask<br>Combiner</p>
<p>MapReduce编程<br>Mapper怎么写<br>Reducer怎么写<br>Job 怎么写</p>
<ol>
<li>去重</li>
<li>计数 wordcount</li>
<li>统计总分，均分</li>
<li>好友推荐</li>
<li>排序</li>
<li>表的合并</li>
</ol>
<p>Hive是什么<br>给你几张表会写sql语句查询<br>id     月份    次数<br>1001   2020-1  1<br>1002   2020-2  3<br>1001   2020-2  5<br>1003   2020-3  6<br>1002   2020-10  3<br>1003   2020-4  1<br>1001   2020-3  2<br>1001   2020-4  1<br>1002   2020-11  2<br>1004   2020-10  4</p>
<p>统计用户累计访问次数，和单月最大次数</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-Coding-Is-Fun" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T08:25:48.000Z"><a href="/2022/08/09/Coding-Is-Fun/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/Coding-Is-Fun/">Coding_Is_Fun</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>About 137,000,000 results (0.51 seconds) </p>
<h1 id="Search-Results"><a href="#Search-Results" class="headerlink" title="Search Results"></a>Search Results</h1><h2 id="Local-Time"><a href="#Local-Time" class="headerlink" title="Local Time"></a>Local Time</h2><p>Hong Kong Standard Time</p>
<p>Time zone in Hong Kong (GMT+8)</p>
<p>Tuesday, August 9, 2022, 4:17 PM</p>
<p><a target="_blank" rel="noopener" href="https://www.google.com/search?q=time+zone+hong+kong&oq=time+zone+hong+kong&aqs=chrome..69i57j0i131i395i433i512j0i395i402l2j0i395i433i457i512j0i131i433i512j0i512j0i131i433i512j0i512j0i131i433i512.4160j1j7&sourceid=chrome&ie=UTF-8#">Feedback</a></p>
<h3 id="People-also-ask"><a href="#People-also-ask" class="headerlink" title="People also ask"></a>People also ask</h3><p>What time zone does Hong Kong use?</p>
<p>Is Hong Kong Time GMT?</p>
<p>Is Hong Kong on China Standard Time?</p>
<p>How far ahead is Hong Kong Time?</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="as_sitesearch" value="wiserdi.github.io">
  </form>
</div>


  

  
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2022 Admin
  
</div>
<div class="clearfix"></div></footer>
  
<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/jquery.imagesloaded.min.js"></script>


<script src="/js/gallery.js"></script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script src="/fancybox/jquery.fancybox.pack.js"></script>

<script>
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>

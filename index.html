<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  <title>The World to Affluence</title>
  <meta name="author" content="Admin">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="The World to Affluence"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

  <!--[if lt IE 9]><script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script><![endif]-->
  

<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">The World to Affluence</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/null">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article id="post-kuroda-seiki" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T16:32:07.000Z"><a href="/2022/08/10/kuroda-seiki/">2022-08-10</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/10/kuroda-seiki/">Kuroda Seiki</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p><img src="/./kuroda_seiki/image-20220810003244150.png" alt="image-20220810003244150"></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kazoku">Viscount</a> <strong>Kuroda Seiki</strong> (黒田 清輝, August 9, 1866 – July 15, 1924) was a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Japanese_people">Japanese</a> painter and teacher, noted for bringing Western art theory and practice to a wide Japanese audience.</p>
<p>He was among the leaders of the <em><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Y%C5%8Dga">yōga</a></em> (or Western-style) movement in late 19th and early 20th-century <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Japanese_painting">Japanese painting</a>, and has come to be remembered in Japan as “the father of Western-style painting.”</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-flume" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T12:53:54.000Z"><a href="/2022/08/09/flume/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/flume/">flume 学习笔记</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Flume 是一种分布式、可靠且可用的服务，用于高效收集、聚合和移动大量日志数据。它具有基于流数据流的简单灵活的架构。它具有可调整的可靠性机制以及许多故障转移和恢复机制，具有健壮性和容错性。它使用简单可扩展数据模型允许在线分析应用程序。</p>
<p><img src="/DevGuide_image00.png" alt="Agent component diagram"></p>
<p>实时读取服务器上的日志数据，将数据写入到HDFS</p>
<h3 id="Flume的优点"><a href="#Flume的优点" class="headerlink" title="Flume的优点"></a>Flume的优点</h3><ol>
<li><p>可以和任意存储进程集成</p>
</li>
<li><p>输入的数据速率大于写入目的的存储速率，Flume会进行缓冲，减小hdfs的压力</p>
</li>
<li><p>flume中在channel上支持事务，使用了两个事务模型(sender + reciever)，确保消息可靠发送</p>
<p>source-&gt;channel 和channel-&gt;sink ，只有事务中的所有的数据全部提交到channel，那么source才认为数据读取完成，同理，只有所有数据都别写出sink，才会从channel中移除</p>
</li>
</ol>
<h3 id="Flume的架构"><a href="#Flume的架构" class="headerlink" title="Flume的架构"></a>Flume的架构</h3><p><strong>Source</strong> 数据输入端的类型: </p>
<p>Avro Source<br>Thrift Source<br>Exec Source<br>JMS Source<br>JMS message converter<br>SSL and JMS Source<br>Spooling Directory Source<br>Event Deserializers<br>LINE<br>AVRO<br>BlobDeserializer<br>Taildir Source<br>Twitter 1% firehose Source (experimental)<br>Kafka Source<br>NetCat TCP Source<br>NetCat UDP Source<br>Sequence Generator Source<br>Syslog Sources<br>Syslog TCP Source<br>Multiport Syslog TCP Source<br>Syslog UDP Source<br>HTTP Source<br>JSONHandler<br>BlobHandler<br>Stress Source<br>Legacy Sources<br>Avro Legacy Source<br>Thrift Legacy Source<br>Custom Source<br>Scribe Source</p>
<p><strong>Sink</strong> 目的地的类型：</p>
<p>HDFS Sink<br>Hive Sink<br>Logger Sink<br>Avro Sink<br>Thrift Sink<br>IRC Sink<br>File Roll Sink<br>Null Sink<br>HBaseSinks<br>HBaseSink<br>HBase2Sink<br>AsyncHBaseSink<br>MorphlineSolrSink<br>ElasticSearchSink<br>Kite Dataset Sink<br>Kafka Sink<br>HTTP Sink<br>Custom Sink</p>
<p><strong>Channel</strong> 是source sink之间的缓冲，类型有:</p>
<p>Memory Channel : 基于内存的，你不关心日志是否丢失<br>JDBC Channel<br>Kafka Channel<br>File Channel ：保证数据不丢失，写入channel的数据会被持久化<br>Spillable Memory Channel<br>Pseudo Transaction Channel<br>Custom Channel</p>
<h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><ol>
<li><p>下载地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://flume.apache.org/download.html</span><br></pre></td></tr></table></figure>
</li>
<li><p>上传到&#x2F;opt&#x2F;software下</p>
</li>
<li><p>解压缩，记得切换到hadoop用户</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
</li>
<li><p>做软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s apache-flume-1.9.0-bin flume</span><br></pre></td></tr></table></figure>
</li>
<li><p>移除有冲突的jar包</p>
<p>将guava-11.0.2.jar包移除，或者改名也行</p>
<p>因为和hadoop下的冲突</p>
<p>&#x2F;opt&#x2F;module&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;guava-27.0-jre.jar</p>
<p>可以把上面的新的cp过来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /opt/module/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /opt/module/lib/</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例一-监控本地端口"><a href="#案例一-监控本地端口" class="headerlink" title="案例一: 监控本地端口"></a>案例一: 监控本地端口</h2><p>NetCat TCP</p>
<p>使用Flume监听一个端口，收集这个端口的数据，打印到控制台，或者输出到文件</p>
<ol>
<li><p>下载安装netcat</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y nc</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置flume的配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir jobs</span><br><span class="line">vi flume-nc.conf</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line"># a1 是agent的名字，随便起，后面启动flume的时候要对应这个名字</span><br><span class="line"># r1 是source的名字</span><br><span class="line">a1.sources = r1</span><br><span class="line"># k1是sink的名字</span><br><span class="line">a1.sinks = k1</span><br><span class="line"># c1是channel的名字</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line"># 配置source</span><br><span class="line"># r1的类型是netcat</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line"># 绑定的ip地址是localhost</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line"># 绑定的端口是44444</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line"># 配置 sink</span><br><span class="line"># sink的类型是日志类型</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line"># 把 source和sink 跟channel 连接起来</span><br><span class="line"># r1的channel是c1</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line"># k1的channel是c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查端口是否被占用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -nlp | grep 44444</span><br><span class="line"></span><br><span class="line">tcp6       0      0 127.0.0.1:44444         :::*                    LISTEN      22600/java  </span><br></pre></td></tr></table></figure>

<p>上面就是44444端口被一个java进程占用，进程id是22600</p>
<p>杀掉进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill 22600</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动flume</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ bin/flume-ng agent --conf conf --conf-file jobs/flume-nc.conf --name 	a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">--conf conf 配置文件在什么地方，跟的是个目录</span><br><span class="line">--conf-file flume本次运行的配置文件(source sink channel的配置)</span><br><span class="line">--name agent的名字</span><br><span class="line">-Dflume.root.logger=INFO,console 运行时参数flume.root.logger修改为INFO,console，让日志在控制台输出，输出的级别是INFO，日志级别DEBUG INFO WARN ERROR</span><br><span class="line"></span><br><span class="line">简写</span><br><span class="line">bin/flume-ng agent -c conf -n a1 -f jobs/flume-nc.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动nc发送数据</p>
<p>打开另外一个远程连接窗口执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc localhost 44444</span><br></pre></td></tr></table></figure>

<p>输入内容</p>
<p>在flume运行的窗口就会收到信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line"></span><br><span class="line">2022-04-21 22:59:31,374 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: E4 BD 95 E5 85 B5 E5 AE B6                      ......... &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例二：实时监控单个文件，保存到hdfs中"><a href="#案例二：实时监控单个文件，保存到hdfs中" class="headerlink" title="案例二：实时监控单个文件，保存到hdfs中"></a>案例二：实时监控单个文件，保存到hdfs中</h2><ol>
<li><p>配置下hdfs</p>
<p>之前的服务器已经配好了&#x2F;etc&#x2F;profiled.d&#x2F;hadoop_env.sh</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_202</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line"># HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>创建flume配置文件</p>
<p>jobs&#x2F;flume-file-hdfs.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line"># 命令是tail -F</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/njust.log</span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/flume-ng agent -c conf -n a1 -f jobs/flu-file-hdfs.conf </span><br></pre></td></tr></table></figure>

<p>往&#x2F;tmp&#x2F;njust.log里面加东西</p>
<p> 观察hdfs的目录</p>
</li>
</ol>
<h2 id="案例三-实时监控目录"><a href="#案例三-实时监控目录" class="headerlink" title="案例三: 实时监控目录"></a>案例三: 实时监控目录</h2><p>只监控目录下的新文件，.complete就不管了</p>
<ol>
<li><p>配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source spooldir 监控目录的source</span><br><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line"># 配置监控目录</span><br><span class="line">a1.sources.r1.spoolDir = /tmp/hadoop</span><br><span class="line"># 是否添加文件绝对路径当文件头</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line"># 文件上传好以后，会被改名，后缀是什么</span><br><span class="line">a1.sources.r1.fileSuffix = .COMPLETED</span><br><span class="line"># includePattern 可以用正则表达式来配置哪些文件名的文件要上传</span><br><span class="line"># ignorePattern 哪些忽略</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"># 多久生成一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.rollInterval = 60</span><br><span class="line"># 一次写100个Event到hdfs</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>


</li>
<li><p>运行</p>
</li>
</ol>
<h2 id="案例四-实时监控目录下多个文件追加"><a href="#案例四-实时监控目录下多个文件追加" class="headerlink" title="案例四 实时监控目录下多个文件追加"></a>案例四 实时监控目录下多个文件追加</h2><p>exec source 是一个文件</p>
<p>Taildir source 适用监听多个追加文件，而且支持断点续传</p>
<ol>
<li><p>配置flume-taildir-hdfs.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source taildir 监控目录下的多个文件追加</span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.positionFile = /tmp/hadoop/taildir_position.json</span><br><span class="line"># 指示有几个文件组，中间用空格分开</span><br><span class="line">a1.sources.r1.filegroups = f1 f2</span><br><span class="line"># 定义f1文件组的文件，可以是单个文件</span><br><span class="line">a1.sources.r1.filegroups.f1 = /tmp/hadoop/test1/example.log</span><br><span class="line">a1.sources.r1.headers.f1.headerKey1 = value1</span><br><span class="line">a1.sources.r1.filegroups.f2 = /tmp/hadoop/test2/.*log.*</span><br><span class="line">a1.sources.r1.headers.f2.headerKey1 = value2</span><br><span class="line">a1.sources.r1.headers.f2.headerKey2 = value2-2</span><br><span class="line"># 日志里面用文件的绝对路径做头</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line">a1.sources.ri.maxBatchCount = 1000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://hadoop201:8020/events/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"># 多久生成一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.rollInterval = 60</span><br><span class="line"># 一次写100个Event到hdfs</span><br><span class="line">a1.sinks.k1.hdfs.hdfs.hdfs.batchSize = 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Flume-事务"><a href="#Flume-事务" class="headerlink" title="Flume 事务"></a>Flume 事务</h2><p>Flume agent中间有三个组件，source  channel  sink，里面流的东西是event ，event由head和body组成</p>
<p>事务分两个部分</p>
<h3 id="put事务"><a href="#put事务" class="headerlink" title="put事务"></a>put事务</h3><p>source -&gt; channel的部分 </p>
<p><img src="/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Nhc2Vab2VjeGw=,size_16,color_FFFFFF,t_70#pic_center.png" alt="在这里插入图片描述"></p>
<p>首先Source会采集一批数据，封装为event，缓存达到batch data的最大容量时（batch data的大小取决于配置参数batch size的值），Flume开启事务：</p>
<p>doPut（）:将这批event写入到临时缓冲区putList，putList是一个LinkedBlockingDeque<br>，大小取决于配置Channel的参数transaction capacity的大小。</p>
<p>doCommit（）:检查channel内存队列是否足够合并，内存队列的大小由Channel的capacity参数控制， Channel的容量内存队列足够的时候，提交event成功。</p>
<p>doRollback（）: channel内存队列空间不够时，回滚，这里会将整个putList中的数据都扔掉，然后给Source返回一个ChannelException异常，告诉Source数据没有采集上。Source会重新采集这批数据，然后开启新的事务。</p>
<h3 id="Take事务"><a href="#Take事务" class="headerlink" title="Take事务"></a>Take事务</h3><p>channel -&gt; sink </p>
<p><img src="/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Nhc2Vab2VjeGw=,size_16,color_FFFFFF,t_70#pic_center-16511116964952.png" alt="在这里插入图片描述"></p>
<p>doTake（）：sink将数据剪切取到临时缓冲区takeList，takeList也是一个LinkedBlockingDeque，<br>大小取决于配置Channel的参数transaction capacity的大小，同时也拷贝一份放入写往HDFS的IO流中。</p>
<p>doCommit（）：如果event全部发送成功，就清除takeList。</p>
<p>doRollback（）：如果发送过程中出现异常，回滚，将takeList中的全部event归还给Channel。这个操作可能导致数据重复,如果已经写入一半的event到了HDFS，但是回滚时会向channel归还整个takeList中的event，后续再次开启事务向HDFS写入这批event时候，就出现了数据重复。</p>
<p>Flume的事务仅能保证两个传输阶段的数据不丢，但是如果channel选用的是memory channel，那么由于memory channel将数据存储在内存中，一旦channel发生异常，数据仍然可能丢失，但采用File channel时，数据传输到channel时会落盘，再结合事务，会保证整体上数据不会丢失，但是仍然可能会在take事务阶段发生数据重复。</p>
<h2 id="Flume-重要组件"><a href="#Flume-重要组件" class="headerlink" title="Flume 重要组件"></a>Flume 重要组件</h2><p><img src="/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxNDY4MQ==,size_16,color_FFFFFF,t_70#pic_center.png" alt="在这里插入图片描述"></p>
<ol>
<li><p>Flume Channel Selectors ( 3 种 )</p>
<p>作用就是选出event该去哪个channel，默认就是replicating（复制）</p>
<p>Replicating Channel Selector</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2 c3</span><br><span class="line"># 定义channel的选择器是复制, 将source来的一个event  c1 c2 c3都复制发一份</span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line"># 定义了3个channel</span><br><span class="line">a1.sources.r1.channels = c1 c2 c3</span><br><span class="line"># c3如果数据出问题，不管，c1 c2没配置，则必须执行事务</span><br><span class="line">a1.sources.r1.selector.optional = c3</span><br></pre></td></tr></table></figure>

<p>Multiplexing Channel Selector</p>
<p>会将event根据条件发到不同的channel</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2 c3 c4</span><br><span class="line">a1.sources.r1.selector.type = multiplexing</span><br><span class="line">a1.sources.r1.selector.header = state</span><br><span class="line">a1.sources.r1.selector.mapping.CZ = c1</span><br><span class="line">a1.sources.r1.selector.mapping.US = c2 c3</span><br><span class="line">a1.sources.r1.selector.default = c4</span><br></pre></td></tr></table></figure></li>
</ol>
<p>​		Custom Channel Selector  自定义的</p>
<p>​		implementation of the ChannelSelector interface</p>
<ol start="2">
<li><p>Flume Sink Processors</p>
<p>Default Sink Processor：对应单个sink</p>
<p>Failover Sink Processor: 维护一个有优先级的水池列表，确保 event一定会被处理（送达）,失败的会处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br><span class="line"># 必配 sink优先级，数字越大优先级越高</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 5</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 10</span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br></pre></td></tr></table></figure>

<p>Load balancing Sink Processor：实现负载均衡sinks</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.backoff = true</span><br><span class="line">a1.sinkgroups.g1.processor.selector = random</span><br></pre></td></tr></table></figure>


</li>
<li><p>Flume Interceptors</p>
<p>flume在执行中有能力去修改和丢弃event，Interceptors拦截器就是做这个的</p>
</li>
</ol>
<h2 id="Flume的拓扑结构"><a href="#Flume的拓扑结构" class="headerlink" title="Flume的拓扑结构"></a>Flume的拓扑结构</h2><ol>
<li><p>串联</p>
<p><img src="/UserGuide_image03.png" alt="Two agents communicating over Avro RPC"></p>
</li>
</ol>
<p>​      将多个flume按顺序连接起来，不建议串联太长，因为如果中间一个出问题，整个通道就都完了</p>
<ol start="2">
<li>Consolidation 合并</li>
</ol>
<p><img src="/UserGuide_image02.png" alt="A fan-in flow using Avro RPC to consolidate events in one place"></p>
<p>​        大多数情况用这种，工作环境，服务器会非常多，将多个服务器的数据采集汇总，给每台服务器配一个flume，然后传送到一个统一的sink去汇总处理，日志分析</p>
<ol start="3">
<li>Multiplexing the flow 多路复用</li>
</ol>
<p><img src="/UserGuide_image01.png" alt="A fan-out flow using a (UserGuide_image01.png) channel selector"></p>
<p>​      支持将source分发到不同的channel，多个目的地</p>
<ol start="4">
<li><p>Load-Balance负载均衡和Failover 故障切换</p>
<p><img src="/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxNDY4MQ==,size_16,color_FFFFFF,t_70#pic_center-16511166368648.png" alt="在这里插入图片描述"></p>
</li>
</ol>
<p>将多个sink 组成一个组，sink组实现负载均衡和故障切换</p>
<h2 id="案例五-多路"><a href="#案例五-多路" class="headerlink" title="案例五 多路"></a>案例五 多路</h2><p>有一个FlumeA监控文件，会把变动发到FlumeB，FlumeB负责写入hdfs，FlumeA还会发送给FlumeC，FlumeC就直接输出到本地console或者文件</p>
<p><img src="/image-20220428115518751-165111812064810.png" alt="image-20220428115518751"></p>
<ol>
<li><p>配置文件 flume-file-flume.conf 用来将日志的内容发送到2个channel，两个sink</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line"># 配置 selector</span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/njust.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># 配置sink k1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop201</span><br><span class="line">a1.sinks.k1.port = 4545</span><br><span class="line"># 配置sink k2</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop201</span><br><span class="line">a1.sinks.k2.port = 4646</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># c2的类型是memory channel</span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line"># c2最多能容纳1000个event</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line"># c2的事务提交100个提交一次</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置文件 flume-flume-hdfs.conf 从flume到hdfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.channels = c3</span><br><span class="line">a2.sinks = k3</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a2.sources.r2.type = avro</span><br><span class="line">a2.sources.r2.bind = hadoop201</span><br><span class="line">a2.sources.r2.port = 4545</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置sink</span><br><span class="line">a2.sinks.k3.type = hdfs</span><br><span class="line"># hdfs的路径 要写全称hdfs://namenode:port/path 路径可以用通配符去生成</span><br><span class="line">a2.sinks.k3.hdfs.path = hdfs://hadoop201:8020/events2/%y-%m-%d/%H%M</span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a2.sinks.k3.hdfs.filePrefix = events-</span><br><span class="line"># 是否应该按时间滚动文件夹</span><br><span class="line">a2.sinks.k3.hdfs.round = true</span><br><span class="line"># 10分钟生成一个文件夹</span><br><span class="line">a2.sinks.k3.hdfs.roundValue = 10</span><br><span class="line"># 定义时间单位</span><br><span class="line">a2.sinks.k3.hdfs.roundUnit = minute</span><br><span class="line"># 使用本地时间戳</span><br><span class="line">a2.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c3的类型是memory channel</span><br><span class="line">a2.channels.c3.type = memory</span><br><span class="line"># c3最多能容纳1000个event</span><br><span class="line">a2.channels.c3.capacity = 1000</span><br><span class="line"># c3的事务提交100个提交一次</span><br><span class="line">a2.channels.c3.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a2.sources.r2.channels = c3</span><br><span class="line">a2.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure>


</li>
<li><p>配置文件 flume-flume-local.conf 从flume到本地</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a3.sources = r3</span><br><span class="line">a3.channels = c4</span><br><span class="line">a3.sinks = k4</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a3.sources.r3.type = avro</span><br><span class="line">a3.sources.r3.bind = hadoop201</span><br><span class="line">a3.sources.r3.port = 4646</span><br><span class="line"></span><br><span class="line"># 配置sink file roll sink</span><br><span class="line">a3.sinks.k4.type = file_roll</span><br><span class="line"># 不会自动建目录，请一定要提前建好目录</span><br><span class="line">a3.sinks.k4.sink.directory = /tmp/hadoop/logs</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c4的类型是memory channel</span><br><span class="line">a3.channels.c4.type = memory</span><br><span class="line"># c4最多能容纳1000个event</span><br><span class="line">a3.channels.c4.capacity = 1000</span><br><span class="line"># c4的事务提交100个提交一次</span><br><span class="line">a3.channels.c4.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a3.sources.r3.channels = c4</span><br><span class="line">a3.sinks.k4.channel = c4</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="案例六-合并"><a href="#案例六-合并" class="headerlink" title="案例六 合并"></a>案例六 合并</h2><img src="/2022/08/09/flume/image-20220428145440550.png" alt="image-20220428145440550" style="zoom: 50%;">

<ol>
<li><p>配置a1 flume-file-avro.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/hadoop/test1/example.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># 配置sink k1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop203</span><br><span class="line">a1.sinks.k1.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c1的类型是memory channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置a2 flume-nc-avro.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.channels = c2</span><br><span class="line">a2.sinks = k2</span><br><span class="line"></span><br><span class="line"># 配置 source</span><br><span class="line"># r2的类型是netcat</span><br><span class="line">a2.sources.r2.type = netcat</span><br><span class="line"># 绑定的ip地址是localhost</span><br><span class="line">a2.sources.r2.bind = hadoop202</span><br><span class="line"># 绑定的端口是44444</span><br><span class="line">a2.sources.r2.port = 44444</span><br><span class="line"></span><br><span class="line"># 配置sink k2</span><br><span class="line">a2.sinks.k2.type = avro</span><br><span class="line">a2.sinks.k2.hostname = hadoop203</span><br><span class="line">a2.sinks.k2.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置channel </span><br><span class="line"># c2的类型是memory channel</span><br><span class="line">a2.channels.c2.type = memory</span><br><span class="line"># c1最多能容纳1000个event</span><br><span class="line">a2.channels.c2.capacity = 1000</span><br><span class="line"># c1的事务提交100个提交一次</span><br><span class="line">a2.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a2.sources.r2.channels = c2</span><br><span class="line">a2.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置a3 flume-avro-logger.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 命名组件</span><br><span class="line">a3.sources = r3</span><br><span class="line">a3.channels = c3</span><br><span class="line">a3.sinks = k3</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line"># source 一个可执行的命令</span><br><span class="line">a3.sources.r3.type = avro</span><br><span class="line">a3.sources.r3.bind = hadoop203</span><br><span class="line">a3.sources.r3.port = 4545</span><br><span class="line"></span><br><span class="line"># 配置sink logger</span><br><span class="line">a3.sinks.k3.type = logger</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line"># c3的类型是memory channel</span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line"># c3最多能容纳1000个event</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line"># c3的事务提交100个提交一次</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 连接起来</span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p>有时不能满足实际需求，需要自定义Source和Sink</p>
<h3 id="案例一：自定义Source"><a href="#案例一：自定义Source" class="headerlink" title="案例一：自定义Source"></a>案例一：自定义Source</h3><p>输出自定义的内容，然后在控制台用logger输出</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.edu.njust.flume;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Maps;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.EventDeliveryException;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.PollableSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.event.EventBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.source.AbstractSource;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> notre</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/5/4</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySource</span> <span class="keyword">extends</span> <span class="title class_">AbstractSource</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span>, PollableSource &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义的属性为将来在job文件中配置的属性</span></span><br><span class="line">  <span class="keyword">private</span> String content;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> delay;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 这个方法的作用就是在配置的配置文件中读属性</span></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    content = context.getString(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;今天天气真好&quot;</span>);</span><br><span class="line">    delay = context.getLong(<span class="string">&quot;delay&quot;</span>,<span class="number">2000L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      <span class="comment">// 创建一个空的头</span></span><br><span class="line">      Map&lt;String,String&gt; headMap = Maps.newHashMap();</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// 创建一个用来传递数据的Event</span></span><br><span class="line">        <span class="type">Event</span> <span class="variable">event</span> <span class="operator">=</span> EventBuilder.withBody(content+i, Charset.forName(<span class="string">&quot;UTF-8&quot;</span>),headMap);</span><br><span class="line">        <span class="comment">// 配置文件中配置了哪个channel连接到这个source，他就去拿哪个channel</span></span><br><span class="line">        getChannelProcessor().processEvent(event);</span><br><span class="line">        <span class="comment">// 休眠下（可以取消）</span></span><br><span class="line">        Thread.sleep(delay);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status.READY;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getBackOffSleepIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getMaxBackOffSleepInterval</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>idea如何打包</p>
<ol>
<li>先build module</li>
<li>在 project structure中添加一个artifact，配置为jar add–&gt;from modules with dependency</li>
<li>在右侧output layer中删除所有的dependency,保留Compile output的那个jar包</li>
</ol>
<p>在项目的out目录下找到打好的jar包</p>
<p>上传到flume下的lib目录下</p>
<p>修改jar包的权限<code>sodu chown hadoop:hadoop FlumeDemo.jar </code></p>
<p>配置jobs文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = cn.edu.njust.flume.MySource</span><br><span class="line">a1.sources.r1.content = hello</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -c conf -n a1 -f jobs/flume-mysource.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>



<h3 id="案例二：自定义Sink"><a href="#案例二：自定义Sink" class="headerlink" title="案例二：自定义Sink"></a>案例二：自定义Sink</h3><p>Sink一定要启动事务，从channel中拿取events，然后写入文件或者hdfs…</p>
<p>自定义一个Sink，监听netcat内容，加上前后缀，输出到Logger</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.edu.njust.flume;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Channel;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.EventDeliveryException;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Transaction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.sink.AbstractSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> notre</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2022/5/4</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySink</span> <span class="keyword">extends</span> <span class="title class_">AbstractSink</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LoggerFactory.getLogger(MySink.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String prefix;</span><br><span class="line">  <span class="keyword">private</span> String suffix;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    prefix = context.getString(<span class="string">&quot;prefix&quot;</span>,<span class="string">&quot;begin-&quot;</span>);</span><br><span class="line">    suffix = context.getString(<span class="string">&quot;suffix&quot;</span>, <span class="string">&quot;-end&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Channel</span> <span class="variable">ch</span> <span class="operator">=</span> getChannel();</span><br><span class="line">    Event event;</span><br><span class="line">    <span class="type">Transaction</span> <span class="variable">tx</span> <span class="operator">=</span> ch.getTransaction();</span><br><span class="line">    tx.begin();</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      event = ch.take();</span><br><span class="line">      <span class="keyword">if</span>(event!=<span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      LOGGER.info(prefix+ <span class="keyword">new</span> <span class="title class_">String</span>(event.getBody())+suffix);</span><br><span class="line">      tx.commit();</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">      tx.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status.READY;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = cn.edu.njust.flume.MySink</span><br><span class="line">a1.sinks.k1.prefix = njust-</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f jobs/flume-mysink.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-virtualizatoin-and-cloud-computing-final-exam-preparation" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T11:27:00.000Z"><a href="/2022/08/09/virtualizatoin-and-cloud-computing-final-exam-preparation/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/virtualizatoin-and-cloud-computing-final-exam-preparation/">2022《虚拟化与云计算应用》期末复习</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="云计算的概念-KBX-N4S-fmi"><a href="#云计算的概念-KBX-N4S-fmi" class="headerlink" title="云计算的概念(KBX, N4S, fmi)"></a>云计算的概念(KBX, N4S, fmi)</h3><p><a target="_blank" rel="noopener" href="https://azure.microsoft.com/en-us/overview/what-is-cloud-computing/#cloud-deployment-types">https://azure.microsoft.com/en-us/overview/what-is-cloud-computing/#cloud-deployment-types</a></p>
<p>云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络、服务器、存储、应用软件、服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Simply put, cloud computing is the delivery of computing services—including servers, storage, databases, networking, software, analytics, and intelligence—over the Internet (“the cloud”) to offer faster innovation, flexible resources, and economies of scale. You typically pay only for cloud services you use, helping you lower your operating costs, run your infrastructure more efficiently, and scale as your business needs change.</span><br></pre></td></tr></table></figure>

<p>复习参考：</p>
<p><a target="_blank" rel="noopener" href="https://yangguoping.blog.csdn.net/article/details/109583017">https://yangguoping.blog.csdn.net/article/details/109583017</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.51cto.com/u_14540820/5191589">https://blog.51cto.com/u_14540820/5191589</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/149636372">https://zhuanlan.zhihu.com/p/149636372</a></p>
<h3 id="云计算的优点-dd-v-te-extension-mc"><a href="#云计算的优点-dd-v-te-extension-mc" class="headerlink" title="云计算的优点(dd, v, te(extension), mc)"></a><strong>云计算的优点</strong>(dd, v, te(extension), mc)</h3><p>更快速的交付和部署 Faster delivery and deployment</p>
<p>更高效的虚拟化 More efficient virtualization</p>
<p>更轻松的迁移和扩展 Easier transfer and extension</p>
<p>更简单的管理 Simpler management</p>
<p>更低的成本 Lower cost</p>
<h3 id="云计算的分类"><a href="#云计算的分类" class="headerlink" title="云计算的分类"></a><strong>云计算的分类</strong></h3><p><strong>按运营模式分：</strong></p>
<ol>
<li>公有云 Public cloud</li>
<li>私有云 Private cloud</li>
<li>混合云 Hybrid cloud</li>
<li>社区云 Community cloud</li>
<li>行业云 Industry cloud</li>
</ol>
<p><strong>按提供的服务(Service)分：</strong></p>
<ol>
<li>IaaS基础设施及服务 Infrastructure as a service (IaaS)</li>
<li>PaaS平台及服务 Platform as a service (PaaS)</li>
<li>SaaS软件及服务 Software as a service (SaaS)</li>
<li>CaaS容器及服务 Containers as a service (CaaS)</li>
</ol>
<p>给你一个描述，或者给你一个产品，你要能分辨出是哪种服务</p>
<p>亚马逊的AWS属于IaaS基础设施及服务，Windows Azure属于PaaS平台及服务。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IAAS(infrastructure 基础设施):硬件、裸机、裸金属、亚马逊的AWS</span><br><span class="line">SAAS(software 软件)：Word等各种软件类</span><br><span class="line">PAAS(platform 平台):亚马逊的平台、Microsoft Azure		</span><br><span class="line">CAAS(container 容器): Docker</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="云计算机制"><a href="#云计算机制" class="headerlink" title="云计算机制"></a><strong>云计算机制</strong></h3><p>云计算技术将<u>计算</u>资源、<u>存储</u>资源以及其他各类资源通过<u>网络以服务的形式</u>提供给资源<u>用户</u>。</p>
<p><strong>云存储机制</strong>：数据的安全性、完整性和保密性 (Confidentiality, security, integrity)</p>
<p><strong>云存储按存储等级</strong>：文件、块、数据集和对象存储 (Files, blocks, datasets, objects)</p>
<p>SAN 网络存储 (Storage Area Network)</p>
<h3 id="云基础设施"><a href="#云基础设施" class="headerlink" title="云基础设施"></a><strong>云基础设施</strong></h3><p>逻辑网络边界(logical separation)：将一组相关的基于云的IT资源与云中的其他主体（如非授权用户）<u>隔离</u>开来，其主要功能是网络分段和隔离，以保证区域内的IT设施的相对<u>独立性</u>。</p>
<p>虚拟服务器</p>
<p>云存储设备</p>
<p>云使用监控</p>
<p>资源复制</p>
<h3 id="虚拟化-virtualization-的定义"><a href="#虚拟化-virtualization-的定义" class="headerlink" title="虚拟化(virtualization)的定义"></a><strong>虚拟化(virtualization)的定义</strong></h3><p>虚拟化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是表示计算机资源的抽象方法。通过虚拟化可以用与访问抽象前资源一致的方法访问抽象后的资源。这种资源的抽象方法并不受实现、地理位置或底层资源的物理配置的限制。 </span><br></pre></td></tr></table></figure>

<p>虚拟化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是为某些事物创造的虚拟（相对于真实）版本，如操作系统、计算机系统、存储设备和网络资源等。虚拟化的对象是各种各样的资源,经过虚拟化后的逻辑资源对用户隐藏了不必要的细节，用户可以在虚拟环境中实现其在真实环境中的部分或者全部功能。</span><br></pre></td></tr></table></figure>



<h3 id="虚拟化优点"><a href="#虚拟化优点" class="headerlink" title="虚拟化优点"></a><strong>虚拟化优点</strong></h3><p>虚拟机</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可支持实现物理资源和资源池的动态共享</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">提高资源利用率，特别是针对那些平均需求远低于需要为其提供专用资源的不同负载。</span><br></pre></td></tr></table></figure>

<p>虚拟化技术</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等），予以抽象、转换后呈现出来并可分割、组合为一个或多个电脑配置环境。</span><br></pre></td></tr></table></figure>



<h3 id="虚拟化技术学习了哪几种？"><a href="#虚拟化技术学习了哪几种？" class="headerlink" title="虚拟化技术学习了哪几种？"></a><strong>虚拟化技术学习了哪几种？</strong></h3><ol>
<li>VMware vSphere</li>
<li>KVM</li>
<li>OpenStack</li>
<li>Docker</li>
</ol>
<h3 id="服务器虚拟化"><a href="#服务器虚拟化" class="headerlink" title="服务器虚拟化"></a><strong>服务器虚拟化</strong></h3><p>支撑技术：(CPU, RAM, ROM, DEV&#x2F;IO, Network, Desktop虚拟化)</p>
<p>CPU 虚拟化、内存虚拟化、存储虚拟化、设备与IO 虚拟化、网络虚拟化、桌面虚拟化</p>
<h3 id="虚拟化功能-snapshot-clone-deployment-backup-cluster-hot-add-NUMA"><a href="#虚拟化功能-snapshot-clone-deployment-backup-cluster-hot-add-NUMA" class="headerlink" title="虚拟化功能(snapshot, clone, deployment, backup, cluster, hot-add, NUMA)"></a><strong>虚拟化功能</strong>(snapshot, clone, deployment, backup, cluster, hot-add, NUMA)</h3><p>虚拟机快照、虚拟机克隆、虚拟机按模板部署、虚拟机备份、虚拟化集群、虚拟机资源热添加、NUMA(Non-uniform memory access)</p>
<h3 id="网络常识"><a href="#网络常识" class="headerlink" title="网络常识"></a><strong>网络常识</strong></h3><p>计算机网络按<u>地理范围</u>可分为：</p>
<ol>
<li>局域网LAN(<strong>local area network</strong>)</li>
<li>城域网MAN(<strong>metropolitan area network</strong>)</li>
<li>广域网WAN(<strong>wide area network</strong>)</li>
</ol>
<p>互联网的拓扑结构：<strong>网状型</strong></p>
<h3 id="存储常识"><a href="#存储常识" class="headerlink" title="存储常识"></a><strong>存储常识</strong></h3><p><strong>独立硬盘冗余阵列</strong>（<strong>RAID</strong>, <strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>ndependent <strong>D</strong>isks），旧称<strong>廉价磁盘冗余阵列</strong>（<strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>nexpensive <strong>D</strong>isks），简称<strong>磁盘阵列</strong></p>
<p><strong>raid技术(0,1,5,6)：</strong>raid0 raid1 raid5 raid6</p>
<p>没有冗余：<strong>raid0</strong></p>
<p>冗余最高：<strong>raid1</strong></p>
<h3 id="vSphere"><a href="#vSphere" class="headerlink" title="vSphere"></a><strong>vSphere</strong></h3><p><a target="_blank" rel="noopener" href="https://docs.vmware.com/en/VMware-vSphere/index.html">https://docs.vmware.com/en/VMware-vSphere/index.html</a></p>
<p><strong>vSphere由ESXi和vCenter Server组成</strong></p>
<p>ESXi: VMware <em>ESXi</em> (formerly ESX) is an enterprise-class, type-1 hypervisor developed by VMware for deploying and serving virtual computers. </p>
<p><img src="https://docs.vmware.com/en/VMware-vSphere/images/GUID-5EB66614-1EE8-4F39-8C8B-1E97EEE76791-high.png" alt="img"></p>
<p><strong>例</strong>：vCenter管理多台服务器<strong>（对）</strong></p>
<h3 id="iSCSI-x2F-ˈaɪskvzi-x2F-Internet-Small-Computer-Systems-Interface"><a href="#iSCSI-x2F-ˈaɪskvzi-x2F-Internet-Small-Computer-Systems-Interface" class="headerlink" title="iSCSI &#x2F;ˈaɪskʌzi&#x2F; (Internet Small Computer Systems Interface)"></a>iSCSI <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Help:IPA/English">&#x2F;ˈaɪskʌzi&#x2F;</a> (<em>Internet Small Computer Systems Interface</em>)</h3><p>vCenter Server提供了很多适应现代数据中心的高级特性：</p>
<ol>
<li>vMotion</li>
<li>vSphere HA</li>
<li>vSphere DRS</li>
</ol>
<p>例：(用SCSI协议不是http协议，而是TCP&#x2F;IP)</p>
<h3 id="vMotion实时迁移要求"><a href="#vMotion实时迁移要求" class="headerlink" title="vMotion实时迁移要求"></a><strong>vMotion实时迁移要求</strong></h3><p>（访问存储、千兆网卡、VMKernel、标准虚拟交换机、处理器、端口组）</p>
<p>①源和目标ESXi主机必须都能够访问保存虚拟机文件的共享存储（FC、FCoE或iSCSI）。</p>
<p>②源和目标ESXi主机必须具备千兆以太网卡或更快的网卡。</p>
<p>③源和目标ESXi主机上必须有支持vMotion的VMkernel端口。</p>
<p>④源和目标ESXi主机必须有相同的标准虚拟交换机。</p>
<p>⑤待迁移虚拟机连接到的所有虚拟机端口组在源和目标ESXi主机上都必须存在。</p>
<p>⑥源和目标ESXi主机的处理器必须兼容。</p>
<h3 id="vSphere的安装"><a href="#vSphere的安装" class="headerlink" title="vSphere的安装"></a><strong>vSphere的安装</strong></h3><p><strong>ESXi iSCSI的配置</strong></p>
<ol>
<li><p>在VMware Workstation的虚拟网络编辑器中，添加vmnet2虚拟网络，类型为仅主机模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将vmnet1、vmnet2、vmnet8的网段分别设置为192.168.100.0/24、192.168.200.0/24、192.168.80.0/24。</span><br></pre></td></tr></table></figure>


</li>
<li><p>创建VMware ESXi虚拟机，内存为4GB，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">为虚拟机配置3个网卡，网络类型分别为仅主机模式、NAT模式、vmnet2模式。</span><br></pre></td></tr></table></figure>


</li>
<li><p>安装VMware ESXi 5.5，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将管理网络的IP地址配置为192.168.100.100（仅主机模式）</span><br></pre></td></tr></table></figure>


</li>
<li><p>使用vSphere Client连接到ESXi，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">添加虚拟机端口组ForVM，创建标准交换机，绑定vmnic1网卡。</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加VMkernel端口，名称为iSCSI，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">创建标准交换机，绑定vmnic2网卡，配置IP地址192.168.200.100。</span><br></pre></td></tr></table></figure></li>
</ol>
<ol start="6">
<li><p>在本机安装的Starwind中创建一个20GB的iSCSI目标。</p>
</li>
<li><p>在ESXi中添加iSCSI软件适配器，绑定VMkernel端口iSCSI，使用动态方式添加iSCSI目标服务器。</p>
</li>
<li><p>在ESXi中添加存储器，使用新发现的iSCSI目标，格式化为VMFS-5文件系统，使用全部空间，存储名称为iSCSI-Starwind。</p>
</li>
<li><p>将CentOS的安装光盘ISO上传到存储iSCSI-Starwind。</p>
</li>
<li><p>在ESXi中创建虚拟机CentOS，放在存储iSCSI-Starwind上，内存为1GB。安装操作系统，将IP地址配置为192.168.80.200&#x2F;24，安装完成后，从本机ping虚拟机CentOS的IP地址。</p>
</li>
</ol>
<h3 id="准备虚拟机顺序"><a href="#准备虚拟机顺序" class="headerlink" title="准备虚拟机顺序"></a>准备虚拟机顺序</h3><p>1） 创建虚拟机</p>
<p>2） 安装操作系统</p>
<p>3） 安装vmtools</p>
<p>4） 打补丁</p>
<h3 id="vCenter-虚拟化平台"><a href="#vCenter-虚拟化平台" class="headerlink" title="vCenter 虚拟化平台"></a><strong>vCenter 虚拟化平台</strong></h3><ol>
<li><p>创建一台windows2008 datacenter r2的虚拟机，配置网络为nat，ip地址192.168.220.100，在上面安装vCenter</p>
</li>
<li><p>创建两台虚拟机，分别安装 ESXi 主机，在 VMware Workstation 中为 ESXi 主机按顺序添加四块网卡,分别是vmnet8 NAT模式、vmnet1 仅主机模式、vmnet2仅主机模式、vmnet0桥接模式，将管理网络的vmnet8网卡设置为192.168.136.11和192.168.136.12</p>
</li>
<li><p>创建一台windows2008 datacenter r2虚拟机，在上面安装starwind，配置iscsi，网络为vmnet1，ip地址为192.168.189.50</p>
</li>
<li><p>在vCenter主机中，创建数据中心DC，并添加主机192.168.136.和192.168.136.12</p>
</li>
<li><p>配置两台 ESXi 连接到 iSCSI 网络共享存储</p>
</li>
<li><p>使用共享存储创建虚拟机（centos7最小化安装），配置虚拟机网卡到vmnet0，桥接模式</p>
</li>
<li><p>安装完成后将虚拟机转换为模板，并从模板部署到一台esxi上</p>
</li>
<li><p>配置 VMkernel 接口支持 vMotion</p>
</li>
<li><p>迁移正在运行的虚拟机</p>
</li>
<li><p>在数据中心 DC 的右键菜单中选择新建群集Network Center</p>
</li>
<li><p>设置 VMware EVC</p>
</li>
<li><p>将 ESXi 主机 192.168.136.11 和 192.168.136.12 拖动到群集 Network Center 中</p>
</li>
<li><p>在群集 Network Center 的右键菜单中选择编辑设置，在群集功能中勾选“打开 vSphere DRS</p>
</li>
<li><p>打开 vSphere Client，在群集 Network Center 的右键菜单中选择编辑设置。在群集功能</p>
</li>
</ol>
<p>处勾选“打开 vSphere HA”，点击确定。</p>
<h3 id="vSphere的安装（30分最后大题）"><a href="#vSphere的安装（30分最后大题）" class="headerlink" title="vSphere的安装（30分最后大题）"></a>vSphere的安装（30分最后大题）</h3><p>实验指导书所有的<u>网络拓扑图</u>（十几分）<u>步骤</u>（十几分）（共4网络）（1.1~2.6）</p>
<p><strong>一、安装 ESXi 服务器</strong></p>
<p><img src="/image-20220614202336908.png" alt="image-20220614202336908"></p>
<p><strong>二、管理 VMware 虚拟网络</strong></p>
<p><img src="/image-20220614202358585.png" alt="image-20220614202358585"></p>
<p><strong>三、配置 iSCSI 目标服务器</strong></p>
<p><img src="/image-20220614202418845.png" alt="image-20220614202418845"></p>
<p><strong>四、配置 ESXi 使用 iSCSI 共享存储</strong></p>
<p><img src="/image-20220614202438030.png" alt="image-20220614202438030"></p>
<p><strong>五、安装 vCenter Server</strong></p>
<p><img src="/image-20220614202456913.png" alt="image-20220614202456913"></p>
<p><strong>ESXi iSCSI的配置</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1) 在VMware Workstation的虚拟网络编辑器中，添加vmnet2虚拟网络，类型为仅主机模式。将vmnet1、vmnet2、	vmnet8的网段分别设置为192.168.100.0/24、192.168.200.0/24、192.168.80.0/24。</span><br><span class="line">2) 创建VMware ESXi虚拟机，内存为4GB，为虚拟机配置3个网卡，网络类型分别为仅主机模式、NAT模式、vmnet2模式。</span><br><span class="line">3) 安装VMware ESXi 5.5，将管理网络的IP地址配置为192.168.100.100（仅主机模式）</span><br><span class="line">4) 使用vSphere Client连接到ESXi，添加虚拟机端口组ForVM，创建标准交换机，绑定vmnic1网卡。</span><br><span class="line">5) 添加VMkernel端口，名称为iSCSI，创建标准交换机，绑定vmnic2网卡，配置IP地址192.168.200.100。</span><br><span class="line">6) 在本机安装的Starwind中创建一个20GB的iSCSI目标。</span><br><span class="line">7) 在ESXi中添加iSCSI软件适配器，绑定VMkernel端口iSCSI，使用动态方式添加iSCSI目标服务器。</span><br><span class="line">8) 在ESXi中添加存储器，使用新发现的iSCSI目标，格式化为VMFS-5文件系统，使用全部空间，存储名称为iSCSI-	Starwind。</span><br><span class="line">9) 将CentOS的安装光盘ISO上传到存储iSCSI-Starwind。</span><br><span class="line">10) 在ESXi中创建虚拟机CentOS，放在存储iSCSI-Starwind上，内存为1GB。安装操作系统，将IP地址配置为	192.168.80.200/24，安装完成后，从本机ping虚拟机CentOS的IP地址。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="KVM"><a href="#KVM" class="headerlink" title="KVM"></a><strong>KVM</strong></h3><p>类似VMware workstation，可以虚拟化安装windows也可以装Linux</p>
<h3 id="OpenStack"><a href="#OpenStack" class="headerlink" title="OpenStack"></a><strong>OpenStack</strong></h3><p><strong>Keystone&#x2F;Nova&#x2F;Glance&#x2F;Cinder&#x2F;Swift&#x2F;Neutron</strong></p>
<p>Keystone</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">为OpenStack上的所有服务提供身份认证和授权</span><br></pre></td></tr></table></figure>

<p>Nova</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是OpenStack的控制器，支持OpenStack云内的实例的生命周期所需的所有活动处理。Nova作为管理平台管理着OpenStack云里的计算资源和扩展需求。</span><br></pre></td></tr></table></figure>

<p>Glance</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">提供了一个虚拟磁盘镜像的目录和存储仓库，可以提供对虚拟机镜像的存储和检索。这些磁盘镜像广泛应用于Nova组件之中。Glance能进行多个数据中心的镜像管理和租户私有镜像管理。</span><br></pre></td></tr></table></figure>

<p>Cinder</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cinder组件为虚拟机实例提供了块存储设备，同时为管理存储设备提供了一整套方法</span><br></pre></td></tr></table></figure>

<p>Swift</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">提供对象存储服务，允许对文件进行存储或者检索，但不通过挂载文件服务器上目录的方式来实现。Swift为OpenStack提供了分布式的、最终一致的虚拟对象存储。</span><br></pre></td></tr></table></figure>

<p>Neutron</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">是OpenStack中提供网络服务的核心组件，基于软件定义网络的思想，实现软件化的网络资源管理，在实现上充分利用了Linux操作系统中各种网络相关技术，支持第三方插件。</span><br></pre></td></tr></table></figure>

<p>OpenStack的各个服务之间通过统一的REST风格的API调用，实现系统的<strong>松耦合</strong></p>
<h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a><strong>容器</strong></h3><p>Docker：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">容器container、镜像image、仓库repository</span><br></pre></td></tr></table></figure>

<p>Docker使用沙箱(sandbox)机制，用的namespace实现应用系统之间的隔离</p>
<p>Docker是开源项目</p>
<h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h3><p>Docker</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">是一个开源的应用容器引擎，开发者可以打包他们的应用及依赖(dependency)到一个可移植的容器中，发布到流行的Linux机器上，也可实现虚拟化。</span><br><span class="line">Docker is an open source containerization platform. It enables developers to package applications into containers—standardized executable components combining application source code with the operating system (OS) libraries and dependencies required to run that code in any environment. Containers simplify delivery of distributed applications, and have become increasingly popular as organizations shift to cloud-native development and hybrid multicloud environments.</span><br></pre></td></tr></table></figure>

<p>Kubernetes</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">是一个开源的容器集群管理系统，可以实现容器集群的</span><br><span class="line">自动化部署、自动化扩缩容量、维护等功能。</span><br></pre></td></tr></table></figure>




      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-PicPick-Professional-6-3-0-Multilingual" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T09:42:22.000Z"><a href="/2022/08/09/PicPick-Professional-6-3-0-Multilingual/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/PicPick-Professional-6-3-0-Multilingual/">PicPick Professional 6.3.0 Multilingual</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p><img src="https://sanet.pics/storage-8/0622/xAZd29OgvKR5eZKLzxJeBgoOUzmakKEo.png" alt="PicPick Professional 6.3.0 Multilingual"></p>
<p>File size: 62.3 MB</p>
<p>PicPick - all-in-one design tool for everyone. A full-featured screen capture tool, Intuitive image editor, color picker, color palette, pixel-ruler, protractor, crosshair, whiteboard and more. User friendly and full of features for creating your image. Suitable for software developers, graphic designers and home users.</p>
<p><strong>Capture anything</strong><br>Take screenshots of an entire screen, an active window, the scrolling windows and any specific region of your desktop, etc.</p>
<p><strong>Edit your images</strong><br>Annotate and highlight your images: text, arrows, shapes and more with the built-in image editor that includes the latest Ribbon style menu.</p>
<p><strong>Enhance with effects</strong><br>Easily add effects to your images: drop shadows, frames, watermarks, mosaic, motion blur, brightness control and more.</p>
<p><strong>Share everywhere</strong><br>Save, share, or send your images via Web, email, ftp, Dropbox, Google Drive, SkyDrive, Box, Evernote, Facebook, Twitter and more.</p>
<p><strong>Graphic Accessories</strong><br>Variety of graphic design accessories including color picker, color palette, pixel ruler, protractor, crosshair, magnifier, whiteboard.</p>
<p><strong>Customizable setting</strong><br>With highly advanced settings, you can customize hotkeys, file naming, image quality, and many other options that fits your needs.</p>
<p><a target="_blank" rel="noopener" href="https://anonymz.com/?https://picpick.app/en/download/">What’s new</a></p>
<p><strong>Available On:</strong> Windows 11, 10, 8.1, 8, 7, Vista and XP including both 32-bit and 64-bit versions.</p>
<p>HOMEPAGE</p>
<p><a target="_blank" rel="noopener" href="https://anonymz.com/?https://picpick.app/">https://anonymz.com/...://picpick.app/</a></p>
<p>DOWNLOAD FROM FREE FILE STORAGE</p>
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener" href="https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar">https://nitroflare.com/view/923F060B1FB4594/SaNet.st_PicPick.Pro.6.3.0.rar</a></th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3">https://rapidgator.net/file/0d122eb451ac355d5e08f797ec6487e3</a></td>
</tr>
</tbody></table>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-期末复习" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T09:34:50.000Z"><a href="/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">期末复习</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>Hadoop的核心结构HDFS, MapReduce ，YARN<br>Hadoop的安装<br>5个配置文件 core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml workers<br>启动<br>start-dfs.sh<br>start-yarn.sh</p>
<p>jps查看进程<br>NameNode：它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。<br>SecondaryNameNode：它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。<br>DataNode：它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。<br>ResourceManager（JobTracker）：JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。<br>NodeManager：（TaskTracker）执行任务。</p>
<p>怎么格式化<br>hadoop namenode -foramt<br>文件上传的指令 </p>
<ol>
<li><p>Command-line方式<br>hadoop fs -put &#x2F;xxx &#x2F;xxxx</p>
</li>
<li><p>用API来上传</p>
</li>
</ol>
<p>Configuration conf &#x3D; new Configuration();	<br>conf.set(“fs. defaultFS”,” hdfs:&#x2F;&#x2F;hadoop201:8020”);<br>FileSystem fs &#x3D; FileSystem.get(conf);<br>Path srcPath &#x3D; new Path(“xxx”);<br>Path dstPath &#x3D; new Path(“xxx”);<br>fs.copyFromLocalFile (srcPath, dstPath);<br>fs.close();</p>
<p>HDFS的读写机制<br>写</p>
<ol>
<li>客户端通过FileSystem向NameNode请求上传文件</li>
<li>NameNode检查目标地址，是否存在，目录是否存在，确认是否可以上传</li>
<li>NameNode告诉客户端你要怎么去分割文件</li>
<li>客户端请求第一个block上传到哪几个DataNode</li>
<li>NameNode返回DataNode节点 </li>
<li>客户端通过FSDataOutputStream请求向指定DataNode节点上传数据，</li>
<li>比如副本数量有3个，只传一个节点，然后由这个节点再传给其他2个副本节点</li>
<li>client-&gt;dn1-&gt;dn2-&gt;dn3，客户端第一个数据包发送到dn1后，dn1就会往dn2写</li>
<li>dn2写完第一个就会往dn3传</li>
</ol>
<p>读</p>
<ol>
<li>客户端通过FileSystem向NameNode请求下载文件</li>
<li>NameNode查询Metadata，找到请求的文件在哪个Datanode上</li>
<li>NameNode挑选出一台DataNode（就近原则）,请求读取数据</li>
<li>DataNode开始传输数据给客户端，流的方式</li>
<li>客户端以包为单位接收，先存到本地缓存，然后再写到目标文件</li>
</ol>
<p>MapReduce的优缺点<br>优点：</p>
<ol>
<li><p>高可靠HA High Available<br>数据会被自动保存为多个副本（默认3个），提高了容错性，坏了一个可以自动回复</p>
</li>
<li><p>提高IO性能<br>原理类似raid，一个硬盘的IO吞吐能力是有限的，多副本存在，可以高并发</p>
</li>
<li><p>适合处理大数据<br>数据规模很大的时候，GB TB PB</p>
</li>
<li><p>物美价廉<br>EMC存储,Oracle数据库,IBM服务器   去IOE<br>普通的廉价服务器，通过多副本机制，提高可靠性，就便宜了</p>
</li>
</ol>
<p>缺点：</p>
<ol>
<li><p>不适合低延迟数据访问<br>本地100m 1秒读完，1TB文件，本机10000秒读完，<br>hdfs 100m 连接10s 调配10s 读取1s  21 1TB  连接10s 调配10s 读取3000s<br>只适合较大数据的分析，存取</p>
</li>
<li><p>无法高效处理小文件<br>namenode管理小文件会耗费大量内存和存储信息</p>
</li>
<li><p>写入并发处理不好，修改支持不好<br>支持追加数据，随机修改不支持</p>
</li>
<li><p>不擅长DAG</p>
</li>
</ol>
<p>MapReduce工作流程(看图记住)<br> 执行都是Job<br>MapTask (shuffle)  ReduceTask<br>Combiner</p>
<p>MapReduce编程<br>Mapper怎么写<br>Reducer怎么写<br>Job 怎么写</p>
<ol>
<li>去重</li>
<li>计数 wordcount</li>
<li>统计总分，均分</li>
<li>好友推荐</li>
<li>排序</li>
<li>表的合并</li>
</ol>
<p>Hive是什么<br>给你几张表会写sql语句查询<br>id     月份    次数<br>1001   2020-1  1<br>1002   2020-2  3<br>1001   2020-2  5<br>1003   2020-3  6<br>1002   2020-10  3<br>1003   2020-4  1<br>1001   2020-3  2<br>1001   2020-4  1<br>1002   2020-11  2<br>1004   2020-10  4</p>
<p>统计用户累计访问次数，和单月最大次数</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-Coding-Is-Fun" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2022-08-09T08:25:48.000Z"><a href="/2022/08/09/Coding-Is-Fun/">2022-08-09</a></time>
      
      
  
    <h1 class="title"><a href="/2022/08/09/Coding-Is-Fun/">Coding_Is_Fun</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>About 137,000,000 results (0.51 seconds) </p>
<h1 id="Search-Results"><a href="#Search-Results" class="headerlink" title="Search Results"></a>Search Results</h1><h2 id="Local-Time"><a href="#Local-Time" class="headerlink" title="Local Time"></a>Local Time</h2><p>Hong Kong Standard Time</p>
<p>Time zone in Hong Kong (GMT+8)</p>
<p>Tuesday, August 9, 2022, 4:17 PM</p>
<p><a target="_blank" rel="noopener" href="https://www.google.com/search?q=time+zone+hong+kong&oq=time+zone+hong+kong&aqs=chrome..69i57j0i131i395i433i512j0i395i402l2j0i395i433i457i512j0i131i433i512j0i512j0i131i433i512j0i512j0i131i433i512.4160j1j7&sourceid=chrome&ie=UTF-8#">Feedback</a></p>
<h3 id="People-also-ask"><a href="#People-also-ask" class="headerlink" title="People also ask"></a>People also ask</h3><p>What time zone does Hong Kong use?</p>
<p>Is Hong Kong Time GMT?</p>
<p>Is Hong Kong on China Standard Time?</p>
<p>How far ahead is Hong Kong Time?</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="as_sitesearch" value="wiserdi.github.io">
  </form>
</div>


  

  
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2022 Admin
  
</div>
<div class="clearfix"></div></footer>
  
<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/jquery.imagesloaded.min.js"></script>


<script src="/js/gallery.js"></script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script src="/fancybox/jquery.fancybox.pack.js"></script>

<script>
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
